{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e670e7-6fdc-4f86-888b-69ffbe02ca11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "import backtrader as bt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pytz\n",
    "import time\n",
    "import os\n",
    "from xbbg import blp\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import interact, Dropdown, HBox, VBox, Button, Output, Text, widgets\n",
    "import sympy as sp\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from IPython import get_ipython\n",
    "import matplotlib.dates as mdates\n",
    "from pydataquery import DataQuery\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "import warnings\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import yfinance as yf\n",
    "import csv\n",
    "import uuid\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import warnings\n",
    "from multiprocess import Pool\n",
    "import time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e88dc18-fb8f-4b5c-942a-22eb26ce8d8e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #ER Code\n",
    "# ####################################################\n",
    "\n",
    "# all_start_date = str((datetime.now()-timedelta(days=13*365+1)).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# labels = {\n",
    "#         \"LQD Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_USDLIG_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"HYG Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_USDHY_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"IEAC Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_EURIG_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"IHYG Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_EURHY_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"Fed Fund\": \"FF\",\n",
    "#         \"ER CDX IG 5Y\": \"DB(CDS,TRAC-X,NAMERI100UNF05ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX IG 10Y\": \"DB(CDS,TRAC-X,NAMERI100UNF10ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX HY 5Y\": \"DB(CDS,TRAC-X,NAHY100UNF05ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX HY 10Y\": \"DB(CDS,TRAC-X,NAHY100UNF10ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX EM 5Y\": \"DB(NEO-UK,credit/cds/index/cdxEM-onrun/5y/JPM_RETURN)\",\n",
    "#         \"ER ITRX MAIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX MAIN 10Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/10y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX XOVER 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX SNRFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_senfin-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX SUBFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_subfin-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "# }\n",
    "\n",
    "# dq = DataQuery(\n",
    "# client_id='jbAIMF2Tkp0JO3sc',\n",
    "# client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "# )\n",
    "\n",
    "# job = dq.create_job(expressions = list(labels.values()))\n",
    "# dq.start_date = all_start_date\n",
    "# var = job.execute()\n",
    "# df = job.to_pivot_table()\n",
    "# df = df.T\n",
    "# df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "# df.index.name = 'Date'\n",
    "\n",
    "# df.rename(columns={v:k for k, v in labels.items()},inplace=True)\n",
    "# df.columns.name = None\n",
    "# clear_output(wait=False)\n",
    "# df = df.dropna(how='all')\n",
    "# df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# dq = df.copy()\n",
    "\n",
    "# end_date = dq.index[-1]\n",
    "# ####################################### BBG Data Acquisition\n",
    "\n",
    "# securities = ['HYG US Equity','EMB US Equity','LQD US Equity','VCIT US Equity',\n",
    "#               'IEAC LN Equity','IHYG LN EQUITY', 'BKLN US EQUITY', 'IBCN GR EQUITY',\n",
    "#               'IEI US Equity','IEF US Equity']\n",
    "\n",
    "# fields1 = ['YAS_MOD_DUR']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, end_date = end_date, flds = fields1)\n",
    "# df.columns = [item.split(' ')[0] + ' DUR' for item in securities]\n",
    "# df1 = df.copy()\n",
    "\n",
    "# #################################### Fixing Bad Data Point in YAS of IEI\n",
    "# rolling_avg = df1['IEI DUR'].replace(0, np.nan).rolling(window=30, min_periods=1).mean()\n",
    "# df1['IEI DUR'] = df1.apply(\n",
    "#     lambda row: rolling_avg[row.name] if row['IEI DUR'] == 0.0 else row['IEI DUR'], axis=1\n",
    "# )\n",
    "# #################################### Fixing Bad Data Point in YAS of IEI\n",
    "\n",
    "# securities = ['LT03TRUU INDEX','LT09TRUU INDEX','QW3I INDEX', 'LT03MD INDEX','LT09MD INDEX']\n",
    "# fields = ['PX_LAST']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, end_date = end_date, flds = fields)\n",
    "# df.columns = ['TR ' + item.split(' ')[0] for item in securities[:3]] + [item.split(' ')[0] + ' DUR' for item in securities[:2]]\n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# securities = ['HYG US Equity','EMB US Equity','LQD US Equity','VCIT US Equity','HYGH US Equity','LQDH US Equity',\n",
    "#               'IEI US Equity','IEF US Equity', 'RSP US EQUITY', #'SPX INDEX',  'RTY INDEX',\n",
    "#               'IBCN GR EQUITY',\n",
    "#               'IEAC LN Equity','IHYG LN EQUITY', 'BKLN US EQUITY', 'IWM US EQUITY',\n",
    "#               'GSCBHYEQ Index', 'GSCBIGEQ Index', 'SPY US EQUITY', 'EEM US EQUITY','IJH US EQUITY', 'UVXY US EQUITY',\n",
    "#              ]\n",
    "\n",
    "# fields = ['TOT_RETURN_INDEX_GROSS_DVDS']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, end_date = end_date, flds = fields)\n",
    "# df.columns = ['TR ' + item.split(' ')[0] for item in securities] \n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# securities = ['QW3I INDEX']\n",
    "# fields = ['MODIFIED_DURATION']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, end_date = end_date, flds = fields)\n",
    "# df.columns = [item.split(' ')[0] + ' DUR' for item in securities]\n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# # securities = ['SPXFP INDEX', 'RTYFPE INDEX','SX5EFSER Index']  ############## I want to calculate funding rate for spx, rty and sx5e separately\n",
    "# # fields = ['PX_LAST']\n",
    "# # df = blp.bdh(tickers=securities, start_date = all_start_date, end_date = end_date, flds = fields)\n",
    "# # df.columns = ['ER SPX','ER RTY','ER SX5E']\n",
    "# # df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# securities = ['EURR002W Index']\n",
    "# fields = ['PX_LAST']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, end_date = end_date, flds = fields)\n",
    "# df.columns = ['ECB Rate']\n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# bbg = df1.copy()\n",
    "# dq.index = pd.to_datetime(dq.index)\n",
    "# dq.index = dq.index.date\n",
    "# bbg.index = pd.to_datetime(bbg.index)\n",
    "# bbg.index = bbg.index.date\n",
    "\n",
    "# data = pd.concat([dq,bbg],axis=1)\n",
    "# data = data.sort_index()\n",
    "\n",
    "# df_funding = data[[col for col in data.columns if ('Funding Sprd' in col)]+['Fed Fund']+['ECB Rate']]\n",
    "\n",
    "# if np.isnan(df_funding.loc[df_funding.index[-1],'Fed Fund']):\n",
    "#     df_funding.loc[df_funding.index[-1],'Fed Fund'] = df_funding.loc[df_funding.index[-2],'Fed Fund']\n",
    "\n",
    "# for col in df_funding:\n",
    "#     if col.endswith('Sprd'):\n",
    "#         if col.split(' ')[0] in ['HYG','LQD']:\n",
    "#             df_funding[f'Net Long {col.replace(\" Sprd\",\"\")}'] = (df_funding['Fed Fund'] + df_funding[f'{col}']/100) + 0.25/100\n",
    "#             df_funding[f'Net Short {col.replace(\" Sprd\",\"\")}'] = (df_funding['Fed Fund'] + df_funding[f'{col}']/100) - 0.25/100\n",
    "#         if col.split(' ')[0] in ['IHYG','IEAC']:\n",
    "#             df_funding[f'Net Long {col.replace(\" Sprd\",\"\")}'] = (df_funding['ECB Rate'] + df_funding[f'{col}']/100) + 0.25/100\n",
    "#             df_funding[f'Net Short {col.replace(\" Sprd\",\"\")}'] = (df_funding['ECB Rate'] + df_funding[f'{col}']/100) - 0.25/100\n",
    "\n",
    "# funding_copy_dict = {'VCIT': 'LQD', 'HYGH': 'HYG', 'LQDH': 'LQD'}\n",
    "# for key, val in funding_copy_dict.items():\n",
    "#     df_funding[f'Net Long {key} Funding'] = df_funding[f'Net Long {val} Funding']\n",
    "#     df_funding[f'Net Short {key} Funding'] = df_funding[f'Net Short {val} Funding']\n",
    "\n",
    "# for item in ['EMB','EEM']:\n",
    "#     df_funding[f'Net Long {item} Funding'] = df_funding['Fed Fund'] + 0.5\n",
    "#     df_funding[f'Net Short {item} Funding'] = df_funding['Fed Fund'] - 0.5\n",
    "\n",
    "# for item in ['IEI', 'IEF', 'RSP', 'BKLN', 'GSCBHYEQ', 'GSCBIGEQ', 'SPX', 'RTY', 'SPY', 'IJH','IWM','UVXY']:\n",
    "#     df_funding[f'Net Long {item} Funding'] = df_funding['Fed Fund'] + 0.15\n",
    "#     df_funding[f'Net Short {item} Funding'] = df_funding['Fed Fund'] - 0.15\n",
    "\n",
    "# for item in ['IBCN','SX5E','SX7E']:\n",
    "#     df_funding[f'Net Long {item} Funding'] = df_funding['ECB Rate'] + 0.15\n",
    "#     df_funding[f'Net Short {item} Funding'] = df_funding['ECB Rate'] - 0.15\n",
    "\n",
    "# df_funding = df_funding[[col for col in df_funding.columns if col.startswith(\"Net\")]]\n",
    "# df_funding.index = pd.to_datetime(df_funding.index)\n",
    "# df_funding = df_funding.resample('D').last()\n",
    "\n",
    "# original_er_data = data[[col for col in data.columns if col.startswith(\"ER \")]]\n",
    "# tr_data = data[[col for col in data.columns if col.startswith(\"TR \")]]\n",
    "# ust = tr_data[['TR LT09TRUU']] # for using corr later\n",
    "# tr_data = tr_data.iloc[:,:-3] #dropping LT03/09 and QW3I\n",
    "\n",
    "# tr_data.index = pd.to_datetime(tr_data.index).date\n",
    "# df_funding.index = pd.to_datetime(df_funding.index).date\n",
    "\n",
    "# er_tr_data = pd.concat([tr_data,df_funding],axis=1)\n",
    "# er_tr_data = er_tr_data.sort_index()\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "\n",
    "# etfs = [col for col in er_tr_data.columns if col.startswith(\"TR \")]\n",
    "\n",
    "# for item in etfs:\n",
    "#     er_tr_data[item] = er_tr_data[item].diff()/er_tr_data[item].shift()\n",
    "\n",
    "# er_tr_data['Date'] = pd.to_datetime(er_tr_data.index)\n",
    "# er_tr_data['Days'] = (er_tr_data['Date'] - er_tr_data['Date'].shift()).dt.days\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "# er_tr_data\n",
    "\n",
    "# ############################################################### Funding Sprds\n",
    "# funding = er_tr_data[[col for col in er_tr_data.columns if 'Funding' in col]].copy()\n",
    "# x = er_tr_data[[col for col in er_tr_data.columns if 'Funding' in col]].copy()\n",
    "# x = x.interpolate()\n",
    "# x.to_excel(\"Funding Rates.xlsx\")\n",
    "\n",
    "# # y = x.copy()\n",
    "# # y = round(y,2)\n",
    "# # y.to_excel(\"Funding Rates 2.xlsx\")\n",
    "\n",
    "# ###############################################################\n",
    "# for item in etfs:\n",
    "#     name = item.split(' ')[1]\n",
    "#     er_tr_data[f'ER {name}'] = er_tr_data[item] - \\\n",
    "#                 (1/100)*(er_tr_data['Days']/360)*(0.5*(er_tr_data[f'Net Long {name} Funding'] + er_tr_data[f'Net Short {name} Funding']))\n",
    "\n",
    "\n",
    "# er_tr_data = er_tr_data[[col for col in er_tr_data.columns if col.startswith(\"ER \")]]\n",
    "# er_tr_data = (1+er_tr_data).cumprod()\n",
    "\n",
    "# tr_data.index = pd.to_datetime(tr_data.index).date\n",
    "# df_funding.index = pd.to_datetime(df_funding.index).date\n",
    "\n",
    "# er_tr_data = pd.concat([tr_data,df_funding],axis=1)\n",
    "# er_tr_data = er_tr_data.sort_index()\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "\n",
    "# etfs = [col for col in er_tr_data.columns if col.startswith(\"TR \")]\n",
    "\n",
    "# for item in etfs:\n",
    "#     er_tr_data[item] = er_tr_data[item].diff()/er_tr_data[item].shift()\n",
    "\n",
    "# er_tr_data['Date'] = pd.to_datetime(er_tr_data.index)\n",
    "# er_tr_data['Days'] = (er_tr_data['Date'] - er_tr_data['Date'].shift()).dt.days\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "\n",
    "# for item in etfs:\n",
    "#     name = item.split(' ')[1]\n",
    "#     er_tr_data[f'ER {name}'] = er_tr_data[item] - \\\n",
    "#                 (1/100)*(er_tr_data['Days']/360)*(0.5*(er_tr_data[f'Net Long {name} Funding'] + er_tr_data[f'Net Short {name} Funding']))\n",
    "\n",
    "# er_tr_data = er_tr_data[[col for col in er_tr_data.columns if col.startswith(\"ER \")]]\n",
    "# er_tr_data = (1+er_tr_data).cumprod()\n",
    "\n",
    "# er_data = pd.concat([original_er_data,er_tr_data],axis=1)\n",
    "# # er_data = er_data.dropna()\n",
    "# # er_data.columns = er_data.columns.str.replace(\"ER SPX\",\"ER ESA\").str.replace(\"ER RTY\",\"ER RTYA\").str.replace(\"ER SX5E\",\"ER VGA\")\n",
    "# er_data.columns = er_data.columns.str.replace(\"ER GSCBHYEQ\",\"ER HY Eqty\").str.replace(\"ER GSCBIGEQ\",\"ER IG Eqty\")\n",
    "\n",
    "# securities = ['SPXFP INDEX', 'RTYFPE INDEX','SX5EFSER Index','SX7EFSER Index']\n",
    "# fields = ['PX_LAST']\n",
    "# df = blp.bdh(tickers=securities, start_date = er_data.index[0], end_date = er_data.index[-1], flds = fields)\n",
    "# df.columns = ['ER SPX','ER RTY','ER SX5E','ER SX7E']\n",
    "# er_data = pd.concat([er_data,df], axis=1)\n",
    "# er_data = er_data.sort_index()\n",
    "\n",
    "# ##############################################################\n",
    "\n",
    "# vix = blp.bdh(tickers=['SPVIX2ME Index','VIX INDEX','V2X Index'], flds='PX_LAST', start_date=er_data.index[0])\n",
    "# vix.columns = ['ER SPVIX2ME','ER VIX','ER V2X']\n",
    "# er_data = pd.concat([er_data, vix], axis=1).sort_index().dropna().copy()\n",
    "# er_data.to_csv(\"All ER.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8138fe-14a2-49f3-bc17-33df5ce96e49",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# all_start_date = str((datetime.now()-timedelta(days=13*365+1)).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# labels = {\n",
    "#     \"CDX IG 5Y\": \"DB(CDS,TRAC-X,NAMERI100UNF05ONRUN,JPM_DUR)\",\n",
    "#     \"CDX IG 10Y\": \"DB(CDS,TRAC-X,NAMERI100UNF10ONRUN,JPM_DUR)\",\n",
    "#     \"ITRX MAIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/5y/JPM_DUR)\",\n",
    "#     \"ITRX MAIN 10Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/10y/JPM_DUR)\",\n",
    "#     \"ITRX SNRFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_senfin-onrun/5y/JPM_DUR)\",\n",
    "#     \"ITRX SUBFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_subfin-onrun/5y/JPM_DUR)\",\n",
    "#     \"ITRX XOVER 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/5y/JPM_DUR)\",\n",
    "#     \"ITRX XOVER 10Y\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/10y/JPM_DUR)\"\n",
    "# }\n",
    "\n",
    "# dq = DataQuery(\n",
    "# client_id='jbAIMF2Tkp0JO3sc',\n",
    "# client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "# )\n",
    "\n",
    "# job = dq.create_job(expressions = list(labels.values()))\n",
    "# dq.start_date = all_start_date\n",
    "# var = job.execute()\n",
    "# df = job.to_pivot_table()\n",
    "# df = df.T\n",
    "# df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "# df.index.name = 'Date'\n",
    "\n",
    "# df.rename(columns={v:k for k, v in labels.items()},inplace=True)\n",
    "# df.columns.name = None\n",
    "# clear_output(wait=False)\n",
    "# df = df.dropna(how='all')\n",
    "# df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# dur = df.copy()\n",
    "# dur.to_excel(\"DQ Dur.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a90ef8ca-31ba-44e6-9e58-c130be84d3b7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# all_start_date = str((datetime.now()-timedelta(days=13*365+1)).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# labels = {\n",
    "#     \"CDX IG 5Y\": \"DB(CDS,TRAC-X,NAMERI100UNF05ONRUN,JPM_CDSSPREAD_MID)\",\n",
    "#     \"CDX IG 10Y\": \"DB(CDS,TRAC-X,NAMERI100UNF10ONRUN,JPM_CDSSPREAD_MID)\",\n",
    "#     \"CDX HY 5Y\": \"DB(CDS,TRAC-X,NAHY100UNF05ONRUN,JPM_CLEAN_MID)\",\n",
    "#     \"ITRX MAIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX MAIN 10Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/10y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX SNRFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_senfin-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX SUBFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_subfin-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX XOVER 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX XOVER 10Y\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/10y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"CDX EM 5Y\": \"DB(NEO-UK,credit/cds/index/cdxEM-onrun/5y/JPM_CLEAN_MID)\",\n",
    "# }\n",
    "\n",
    "# dq = DataQuery(\n",
    "# client_id='jbAIMF2Tkp0JO3sc',\n",
    "# client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "# )\n",
    "\n",
    "# job = dq.create_job(expressions = list(labels.values()))\n",
    "# dq.start_date = all_start_date\n",
    "# var = job.execute()\n",
    "# df = job.to_pivot_table()\n",
    "# df = df.T\n",
    "# df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "# df.index.name = 'Date'\n",
    "\n",
    "# df.rename(columns={v:k for k, v in labels.items()},inplace=True)\n",
    "# df.columns.name = None\n",
    "# clear_output(wait=False)\n",
    "# df = df.dropna(how='all')\n",
    "# df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# dur = df.copy()\n",
    "# dur.to_excel(\"DQ Ref Levels_PX_Sprd.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d463e11-9e5a-41ad-a11d-dd701918653a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dict_map = {\n",
    "    # product type, start time, end time, carry (%), trades on sprd, slippage (bps or $),\n",
    "    # fixed commission, notional (if selected as Y; moved to model up look up!), BBG ticker\n",
    "    'CDX IG 5Y': ['CDX', '07:45:00', '16:30:00', 1, 'Yes', 0.15, 300, \"CDX IG CDSI GEN 5Y CORP\"],\n",
    "    'CDX IG 10Y': ['CDX', '07:45:00', '16:30:00', 1, 'Yes', 0.3, 300, \"CDX IG CDSI GEN 10Y CORP\"],\n",
    "    'CDX HY 5Y': ['CDX', '07:45:00', '16:30:00', 5, 'No', 0.02, 300, \"CDX HY CDSI GEN 5Y CORP\"],\n",
    "    'SPX': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"SPX INDEX\"],\n",
    "    'SPY': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"SPY US EQUITY\"],\n",
    "    'RSP': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"RSP US INDEX\"],    \n",
    "    'RTY': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"RTY INDEX\"],\n",
    "    'IG Eqty': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"GSCBIGEQ Index\"],\n",
    "    'HY Eqty': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"GSCBHYEQ Index\"],\n",
    "    'ITRX MAIN 5Y': ['CDX', '03:30:00', '11:59:00', 1, 'Yes', 0.15, 300, \"ITRX EUR CDSI GEN 5Y CORP\"],\n",
    "    'ITRX XOVER 5Y': ['CDX', '03:30:00', '11:59:00', 5, 'Yes', 0.15, 300, \"ITRX XOVER CDSI GEN 5Y CORP\"],\n",
    "    \n",
    "    'VIX': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"VIX INDEX\"],\n",
    "    'V2X': ['Eq', '03:30:00', '11:59:00', 0, 'No', 0.01, 0, \"V2X INDEX\"],\n",
    "    'UVXY': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"UVXY US EQUITY\"],\n",
    "    'SPVIX2ME': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"SPVIX2ME INDEX\"],\n",
    "    \n",
    "    'SX5E': ['Eq', '03:30:00', '11:59:00', 0, 'No', 0.01, 0, \"SX5E INDEX\"],\n",
    "    'SX7E': ['Eq', '03:30:00', '11:59:00', 0, 'No', 0.01, 0, \"SX7E INDEX\"],\n",
    "    'ITRX SNRFIN 5Y': ['CDX', '03:30:00', '11:59:00', 1, 'Yes', 0.15, 300, \"SNRFIN CDSI GEN 5Y CORP\"],\n",
    "    'ITRX SUBFIN 5Y': ['CDX', '03:30:00', '11:59:00', 1, 'Yes', 0.15, 300, \"SUBFIN CDSI GEN 5Y CORP\"],\n",
    "    'CDX EM 5Y': ['CDX', '07:45:00', '16:30:00', 1, 'No', 0.02, 300, \"CDX EM CDSI GEN 5Y CORP\"],\n",
    "\n",
    "    'HYG': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"HYG US EQUITY\"],\n",
    "    'HYGH': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.15, 0, \"HYGH US EQUITY\"],\n",
    "    'EMB': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"EMB US EQUITY\"],\n",
    "    'EEM': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"EEM US EQUITY\"],\n",
    "    'VCIT': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"VCIT US EQUITY\"],\n",
    "    'LQD': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"LQD US EQUITY\"],\n",
    "    'LQDH': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.06, 0, \"LQDH US EQUITY\"],\n",
    "    'IEI': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"IEI US EQUITY\"],\n",
    "    'IEF': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"IEF US EQUITY\"],\n",
    "    'IWM': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"IWM US EQUITY\"],\n",
    "    'IJH': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"IJH US EQUITY\"],\n",
    "}\n",
    "\n",
    "# er_data = pd.read_csv(\"All ER.csv\", index_col=0, parse_dates=True)\n",
    "# er_data.columns = [item.split(\" \",1)[1] for item in er_data.columns]\n",
    "\n",
    "# # df_backup = pd.read_parquet(\"Clean 1min data.parquet\")\n",
    "# # df_backup = pd.read_parquet(\"Clean 1min data v2.parquet\")\n",
    "# # df_backup = pd.read_parquet(\"Clean 1min data v3.parquet\")\n",
    "# # df_backup = pd.read_parquet(\"Clean 1min data v4.parquet\")\n",
    "# df_backup = pd.read_parquet(\"Clean 1min data v5.parquet\")\n",
    "\n",
    "# ##################################################################\n",
    "\n",
    "# bbg_tickers = [dict_map[item][7] for item in dict_map.keys()]\n",
    "# reverse_dict = dict(zip(bbg_tickers, list(dict_map.keys())))\n",
    "# bbg_data = blp.bdh(tickers = bbg_tickers, flds='px_last', start_date='2017-01-01')\n",
    "# bbg_data.columns = bbg_tickers\n",
    "# bbg_data.index = pd.to_datetime(bbg_data.index)\n",
    "# bbg_data.columns = [reverse_dict[item] for item in bbg_data.columns]\n",
    "# ref = pd.read_excel(\"DQ Ref Levels_PX_Sprd.xlsx\", index_col=0, parse_dates=True)\n",
    "\n",
    "# for col in ref.columns:\n",
    "#     bbg_data[col] = ref[col]\n",
    "\n",
    "# bbg_data1 = bbg_data.resample(\"1min\").last().ffill().copy()\n",
    "# bbg_data1.columns = [item +'_bbg_px' for item in bbg_data1.columns]\n",
    "\n",
    "# bbg_data2 = bbg_data.shift().resample(\"1min\").last().ffill().copy()\n",
    "# bbg_data2.columns = [item +'_bbg_px_2' for item in bbg_data2.columns]\n",
    "\n",
    "# ##################################################################\n",
    "\n",
    "# dur = pd.read_excel(\"DQ Dur.xlsx\",index_col=0, parse_dates=True)\n",
    "# dur = dur.shift().resample(\"1min\").last().ffill().copy()  ############ yesterday's duration we take .. we have shifted it here\n",
    "# dur.columns = [item + '_dq_dur' for item in dur.columns]\n",
    "\n",
    "# df = df_backup.copy()\n",
    "# er = er_data.copy()\n",
    "# er.columns = [item + '_dq_ER' for item in er.columns]\n",
    "# er = er.resample(\"1min\").last().ffill().copy()\n",
    "\n",
    "# er2 = er_data.shift().copy()\n",
    "# er2.columns = [item + '_dq_ER_2' for item in er2.columns]\n",
    "# er2 = er2.resample(\"1min\").last().ffill().copy()\n",
    "\n",
    "# ##################################################################\n",
    "# #### V. V. Imp: the dq close is as of 5PM and with bbg_data only till 4PM we don't really 'see' the BBG ER series match the DQ series\n",
    "\n",
    "# intraday_tr_data = None\n",
    "\n",
    "# for col in df.columns:\n",
    "#     # col = \"IEI\"\n",
    "#     if dict_map[col][4] == 'Yes':\n",
    "#         x = pd.concat([df[[col]], er[[f'{col}_dq_ER']], er2[[f'{col}_dq_ER_2']], bbg_data1[[f'{col}_bbg_px']], bbg_data2[[f'{col}_bbg_px_2']],\n",
    "#             dur[[f'{col}_dq_dur']]], axis=1).sort_index().dropna().copy()\n",
    "#         x['TR Change'] = (x[f'{col}_dq_ER'] / x[f'{col}_dq_ER_2'] - 1)\n",
    "#         x['d-o-d sprd pnl'] = (-1) * (x[f'{col}_dq_dur']) * (x[f'{col}_bbg_px'] - x[f'{col}_bbg_px_2']) * 10**(-4)\n",
    "#         x['intraday sprd pnl'] = (-1) * (x[f'{col}_dq_dur']) * (x[col] - x[f'{col}_bbg_px_2']) * 10**(-4)\n",
    "#         x['Calculated TR Change'] = x['TR Change'] - x['d-o-d sprd pnl'] + x['intraday sprd pnl']\n",
    "#         x['Actual TR Series'] = (1 + x['Calculated TR Change']) * x[f'{col}_dq_ER_2']\n",
    "#         x = x[['Actual TR Series']].copy()\n",
    "#         x.columns = [col]\n",
    "#     else:\n",
    "#         x = pd.concat([df[[col]], er[[f'{col}_dq_ER']], er2[[f'{col}_dq_ER_2']], bbg_data1[[f'{col}_bbg_px']], bbg_data2[[f'{col}_bbg_px_2']],\n",
    "#             ], axis=1).sort_index().dropna().copy()\n",
    "#         x['TR Change'] = (x[f'{col}_dq_ER'] / x[f'{col}_dq_ER_2'] - 1)\n",
    "#         if col in [\"CDX HY 5Y\", \"CDX HY 10Y\", \"CDX EM 5Y\"]:\n",
    "#             x['d-o-d px pnl'] = (x[f'{col}_bbg_px'] - x[f'{col}_bbg_px_2']) * 10**(-2)\n",
    "#             x['intraday px pnl'] = (x[col] - x[f'{col}_bbg_px_2']) * 10**(-2)\n",
    "#         else:  ### it is an etf\n",
    "#             x['d-o-d px pnl'] = (x[f'{col}_bbg_px']/ x[f'{col}_bbg_px_2'] - 1)\n",
    "#             x['intraday px pnl'] = (x[col] / x[f'{col}_bbg_px_2'] - 1)\n",
    "#         x['Calculated TR Change'] = x['TR Change'] - x['d-o-d px pnl'] + x['intraday px pnl']\n",
    "#         x['Actual TR Series'] = (1 + x['Calculated TR Change']) * x[f'{col}_dq_ER_2']\n",
    "#         x = x[['Actual TR Series']].copy()\n",
    "#         x.columns = [col]\n",
    "#     intraday_tr_data = pd.concat([intraday_tr_data, x], axis=1)\n",
    "\n",
    "# # intraday_tr_data.to_parquet(\"1min ER series.parquet\")\n",
    "# # intraday_tr_data.to_parquet(\"1min ER series v2.parquet\")\n",
    "# # intraday_tr_data.to_parquet(\"1min ER series v3.parquet\")\n",
    "# # intraday_tr_data.to_parquet(\"1min ER series v4.parquet\")\n",
    "# intraday_tr_data.to_parquet(\"1min ER series v5.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ddff404-30a8-48a7-b14f-4691c9fbbdc3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# t = time.time()\n",
    "# # bbg_px = pd.read_excel(\"10min data with EUv11.xlsx\", index_col=0, parse_dates=True)\n",
    "# p = pd.read_excel(\"HYGH and LQDH.xlsx\", index_col=0, parse_dates=True)\n",
    "# p = p.resample(\"1min\").last().ffill().resample(\"10min\", offset=\"5min\").last().ffill()\n",
    "# p = p[p.index.isin(bbg_px.index)]\n",
    "# b2 = pd.concat([bbg_px, p], axis=1).sort_index()\n",
    "# b2.to_excel(\"10min data with EUv12.xlsx\")\n",
    "\n",
    "# # display(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "455d0189-5320-4a2a-b5ec-c8aa732c626b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>Dur</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Notional</th>\n",
       "      <th>volume</th>\n",
       "      <th>Long Funding P/L</th>\n",
       "      <th>Short Funding P/L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-01 09:35:00</th>\n",
       "      <td>96.33</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.503426</td>\n",
       "      <td>6.301166e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-25 15:55:00</th>\n",
       "      <td>91.37</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.465929</td>\n",
       "      <td>8.224443e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     close  Dur    Signal      Notional  volume  \\\n",
       "2021-07-01 09:35:00  96.33 -1.0  0.503426  6.301166e+06     0.0   \n",
       "2025-04-25 15:55:00  91.37 -1.0  1.465929  8.224443e+06     0.0   \n",
       "\n",
       "                     Long Funding P/L  Short Funding P/L  \n",
       "2021-07-01 09:35:00              -0.0               -0.0  \n",
       "2025-04-25 15:55:00               0.0                0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ZScore Method is Rtn and diff_period_list is [12]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global model is ['HYGH', ['LQDH'], 'HYGH', ['LQDH'], 5000000]\n",
      "model_num is 1\n",
      "trade direction is Long/Short\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>$pnl</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>-4725134.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>-1173302.0</td>\n",
       "      <td>-3969724.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>-157559.0</td>\n",
       "      <td>-918591.0</td>\n",
       "      <td>-3297320.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>277448.0</td>\n",
       "      <td>-166142.0</td>\n",
       "      <td>-954237.0</td>\n",
       "      <td>-3941790.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.25</th>\n",
       "      <td>516073.0</td>\n",
       "      <td>234116.0</td>\n",
       "      <td>20516.0</td>\n",
       "      <td>-970464.0</td>\n",
       "      <td>-3924376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.50</th>\n",
       "      <td>549910.0</td>\n",
       "      <td>303773.0</td>\n",
       "      <td>100104.0</td>\n",
       "      <td>-259986.0</td>\n",
       "      <td>-967384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.75</th>\n",
       "      <td>373355.0</td>\n",
       "      <td>167740.0</td>\n",
       "      <td>20687.0</td>\n",
       "      <td>-148861.0</td>\n",
       "      <td>-207044.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>546325.0</td>\n",
       "      <td>415926.0</td>\n",
       "      <td>425108.0</td>\n",
       "      <td>364889.0</td>\n",
       "      <td>359512.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.50</th>\n",
       "      <td>580807.0</td>\n",
       "      <td>496933.0</td>\n",
       "      <td>583439.0</td>\n",
       "      <td>491051.0</td>\n",
       "      <td>455705.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>291257.0</td>\n",
       "      <td>294820.0</td>\n",
       "      <td>443856.0</td>\n",
       "      <td>352012.0</td>\n",
       "      <td>286882.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "$pnl        0.00       0.25       0.50       0.75       1.00\n",
       "Entry                                                       \n",
       "0.25  -4725134.0        NaN        NaN        NaN        NaN\n",
       "0.50  -1173302.0 -3969724.0        NaN        NaN        NaN\n",
       "0.75   -157559.0  -918591.0 -3297320.0        NaN        NaN\n",
       "1.00    277448.0  -166142.0  -954237.0 -3941790.0        NaN\n",
       "1.25    516073.0   234116.0    20516.0  -970464.0 -3924376.0\n",
       "1.50    549910.0   303773.0   100104.0  -259986.0  -967384.0\n",
       "1.75    373355.0   167740.0    20687.0  -148861.0  -207044.0\n",
       "2.00    546325.0   415926.0   425108.0   364889.0   359512.0\n",
       "2.50    580807.0   496933.0   583439.0   491051.0   455705.0\n",
       "3.00    291257.0   294820.0   443856.0   352012.0   286882.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>$pnl/trade</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>-14539.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>-7570.0</td>\n",
       "      <td>-13277.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>-1770.0</td>\n",
       "      <td>-6424.0</td>\n",
       "      <td>-12585.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>4404.0</td>\n",
       "      <td>-1846.0</td>\n",
       "      <td>-6627.0</td>\n",
       "      <td>-13453.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.25</th>\n",
       "      <td>11219.0</td>\n",
       "      <td>3602.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>-6739.0</td>\n",
       "      <td>-14066.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.50</th>\n",
       "      <td>16664.0</td>\n",
       "      <td>6751.0</td>\n",
       "      <td>1668.0</td>\n",
       "      <td>-3023.0</td>\n",
       "      <td>-7499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.75</th>\n",
       "      <td>14360.0</td>\n",
       "      <td>4659.0</td>\n",
       "      <td>450.0</td>\n",
       "      <td>-2481.0</td>\n",
       "      <td>-2588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>23753.0</td>\n",
       "      <td>12998.0</td>\n",
       "      <td>10628.0</td>\n",
       "      <td>7447.0</td>\n",
       "      <td>6420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.50</th>\n",
       "      <td>36300.0</td>\n",
       "      <td>29231.0</td>\n",
       "      <td>25367.0</td>\n",
       "      <td>18187.0</td>\n",
       "      <td>15714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>32362.0</td>\n",
       "      <td>29482.0</td>\n",
       "      <td>34143.0</td>\n",
       "      <td>25144.0</td>\n",
       "      <td>20492.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "$pnl/trade     0.00     0.25     0.50     0.75     1.00\n",
       "Entry                                                  \n",
       "0.25       -14539.0      NaN      NaN      NaN      NaN\n",
       "0.50        -7570.0 -13277.0      NaN      NaN      NaN\n",
       "0.75        -1770.0  -6424.0 -12585.0      NaN      NaN\n",
       "1.00         4404.0  -1846.0  -6627.0 -13453.0      NaN\n",
       "1.25        11219.0   3602.0    228.0  -6739.0 -14066.0\n",
       "1.50        16664.0   6751.0   1668.0  -3023.0  -7499.0\n",
       "1.75        14360.0   4659.0    450.0  -2481.0  -2588.0\n",
       "2.00        23753.0  12998.0  10628.0   7447.0   6420.0\n",
       "2.50        36300.0  29231.0  25367.0  18187.0  15714.0\n",
       "3.00        32362.0  29482.0  34143.0  25144.0  20492.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SR</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>-4.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>-1.68</td>\n",
       "      <td>-4.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>-0.24</td>\n",
       "      <td>-1.57</td>\n",
       "      <td>-4.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.48</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-1.70</td>\n",
       "      <td>-5.13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.25</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-1.87</td>\n",
       "      <td>-4.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.50</th>\n",
       "      <td>1.18</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>-1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.75</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>1.18</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.50</th>\n",
       "      <td>1.36</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>0.96</td>\n",
       "      <td>1.01</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "SR     0.00  0.25  0.50  0.75  1.00\n",
       "Entry                              \n",
       "0.25  -4.89   NaN   NaN   NaN   NaN\n",
       "0.50  -1.68 -4.94   NaN   NaN   NaN\n",
       "0.75  -0.24 -1.57 -4.53   NaN   NaN\n",
       "1.00   0.48 -0.32 -1.70 -5.13   NaN\n",
       "1.25   0.99  0.53  0.05 -1.87 -4.81\n",
       "1.50   1.18  0.82  0.24 -0.61 -1.87\n",
       "1.75   0.87  0.50  0.06 -0.38 -0.46\n",
       "2.00   1.18  1.12  1.00  0.92  0.87\n",
       "2.50   1.36  1.32  1.40  1.25  1.13\n",
       "3.00   0.96  1.01  1.12  0.93  0.75"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Hit Ratio</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>38.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>54.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.25</th>\n",
       "      <td>61.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.50</th>\n",
       "      <td>64.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.75</th>\n",
       "      <td>62.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>70.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.50</th>\n",
       "      <td>75.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>67.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Hit Ratio  0.00  0.25  0.50  0.75  1.00\n",
       "Entry                                  \n",
       "0.25       14.0   NaN   NaN   NaN   NaN\n",
       "0.50       30.0  15.0   NaN   NaN   NaN\n",
       "0.75       38.0  31.0  17.0   NaN   NaN\n",
       "1.00       54.0  40.0  35.0  16.0   NaN\n",
       "1.25       61.0  49.0  50.0  35.0  15.0\n",
       "1.50       64.0  56.0  50.0  41.0  29.0\n",
       "1.75       62.0  47.0  43.0  43.0  40.0\n",
       "2.00       70.0  59.0  52.0  59.0  59.0\n",
       "2.50       75.0  82.0  70.0  74.0  69.0\n",
       "3.00       67.0  80.0  85.0  79.0  64.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>trades</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>325.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>155.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>89.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>63.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>293.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.25</th>\n",
       "      <td>46.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.50</th>\n",
       "      <td>33.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>129.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.75</th>\n",
       "      <td>26.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>23.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.50</th>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "trades   0.00   0.25   0.50   0.75   1.00\n",
       "Entry                                    \n",
       "0.25    325.0    NaN    NaN    NaN    NaN\n",
       "0.50    155.0  299.0    NaN    NaN    NaN\n",
       "0.75     89.0  143.0  262.0    NaN    NaN\n",
       "1.00     63.0   90.0  144.0  293.0    NaN\n",
       "1.25     46.0   65.0   90.0  144.0  279.0\n",
       "1.50     33.0   45.0   60.0   86.0  129.0\n",
       "1.75     26.0   36.0   46.0   60.0   80.0\n",
       "2.00     23.0   32.0   40.0   49.0   56.0\n",
       "2.50     16.0   17.0   23.0   27.0   29.0\n",
       "3.00      9.0   10.0   13.0   14.0   14.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>days/trade</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>3.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.25</th>\n",
       "      <td>6.7</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.50</th>\n",
       "      <td>7.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.75</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>8.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.50</th>\n",
       "      <td>11.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "days/trade  0.00  0.25  0.50  0.75  1.00\n",
       "Entry                                   \n",
       "0.25         1.7   NaN   NaN   NaN   NaN\n",
       "0.50         3.1   1.7   NaN   NaN   NaN\n",
       "0.75         4.5   3.0   1.8   NaN   NaN\n",
       "1.00         5.7   4.3   2.9   1.3   NaN\n",
       "1.25         6.7   5.6   3.9   2.2   1.0\n",
       "1.50         7.9   6.7   4.8   3.0   1.8\n",
       "1.75         9.0   7.3   5.2   3.5   2.3\n",
       "2.00         8.5   6.6   5.5   3.8   2.7\n",
       "2.50        11.0   9.9   6.0   4.5   3.4\n",
       "3.00         7.0   6.4   4.8   3.6   3.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>max DD</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>-4727512.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>-1183033.0</td>\n",
       "      <td>-3969724.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>-322024.0</td>\n",
       "      <td>-918591.0</td>\n",
       "      <td>-3297320.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>-206010.0</td>\n",
       "      <td>-248514.0</td>\n",
       "      <td>-990758.0</td>\n",
       "      <td>-3991808.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.25</th>\n",
       "      <td>-109836.0</td>\n",
       "      <td>-139138.0</td>\n",
       "      <td>-218406.0</td>\n",
       "      <td>-1001570.0</td>\n",
       "      <td>-3967104.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.50</th>\n",
       "      <td>-101062.0</td>\n",
       "      <td>-165058.0</td>\n",
       "      <td>-199098.0</td>\n",
       "      <td>-430858.0</td>\n",
       "      <td>-1099948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.75</th>\n",
       "      <td>-131510.0</td>\n",
       "      <td>-150049.0</td>\n",
       "      <td>-217576.0</td>\n",
       "      <td>-357955.0</td>\n",
       "      <td>-456695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>-107782.0</td>\n",
       "      <td>-116044.0</td>\n",
       "      <td>-101174.0</td>\n",
       "      <td>-128120.0</td>\n",
       "      <td>-132152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.50</th>\n",
       "      <td>-33489.0</td>\n",
       "      <td>-46268.0</td>\n",
       "      <td>-45217.0</td>\n",
       "      <td>-71060.0</td>\n",
       "      <td>-73803.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>-26711.0</td>\n",
       "      <td>-35385.0</td>\n",
       "      <td>-23243.0</td>\n",
       "      <td>-44636.0</td>\n",
       "      <td>-53364.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "max DD       0.00       0.25       0.50       0.75       1.00\n",
       "Entry                                                        \n",
       "0.25   -4727512.0        NaN        NaN        NaN        NaN\n",
       "0.50   -1183033.0 -3969724.0        NaN        NaN        NaN\n",
       "0.75    -322024.0  -918591.0 -3297320.0        NaN        NaN\n",
       "1.00    -206010.0  -248514.0  -990758.0 -3991808.0        NaN\n",
       "1.25    -109836.0  -139138.0  -218406.0 -1001570.0 -3967104.0\n",
       "1.50    -101062.0  -165058.0  -199098.0  -430858.0 -1099948.0\n",
       "1.75    -131510.0  -150049.0  -217576.0  -357955.0  -456695.0\n",
       "2.00    -107782.0  -116044.0  -101174.0  -128120.0  -132152.0\n",
       "2.50     -33489.0   -46268.0   -45217.0   -71060.0   -73803.0\n",
       "3.00     -26711.0   -35385.0   -23243.0   -44636.0   -53364.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_list = [ \n",
    "    # model_Y, model_X (specify as a list) ### We trade these\n",
    "    # zscore_Y, zscore_X (specify as a list) ### We use these only for generating the zscore; names are taken from BBG datafile\n",
    "\n",
    "    # ['CDX HY 5Y', ['HYGH'], 'CDX HY 5Y', ['HYGH'], 7*10**6],\n",
    "    # ['CDX HY 5Y', ['HYG','IEI'], 'CDX HY 5Y', ['HYG','IEI'], 7*10**6],\n",
    "    # ['CDX EM 5Y', ['EMB','IEF'], 'CDX EM 5Y', ['EMB','IEF'], 9*10**6],\n",
    "    # ['CDX IG 5Y', ['VCIT','IEF'], 'CDX IG 5Y', ['VCIT','IEF'], 25*10**6],\n",
    "\n",
    "    # ['HYGH', ['LQDH'], 'HYGH', ['LQDH'], 5*10**6],\n",
    "    # ['CDX IG 10Y', ['LQD','IEF'], 'CDX IG 10Y', ['LQD','IEF'], 14*10**6],\n",
    "    # ['CDX IG 5Y', ['SPX'],'CDX IG 5Y', ['SPX'],28*10**6],\n",
    "    # ['CDX IG 5Y', ['RSP'],'CDX IG 5Y', ['RSP'],28*10**6],\n",
    "    # ['CDX IG 5Y', ['IWM'],'CDX IG 5Y', ['IWM'],28*10**6],\n",
    "    # ['CDX IG 5Y', ['IJH'],'CDX IG 5Y', ['IJH'],28*10**6],\n",
    "    # # ['CDX IG 5Y', ['IG Eqty'],'CDX IG 5Y', ['IG Eqty'],28*10**6],\n",
    "    # ['CDX IG 5Y', ['VIX'], 'CDX IG 5Y', ['VIX'], 19*10**6],\n",
    "    # ['CDX IG 5Y', ['SPVIX2ME'], 'CDX IG 5Y', ['SPVIX2ME'], 19*10**6],\n",
    "    \n",
    "    # ['CDX HY 5Y', ['SPX'],'CDX HY 5Y', ['SPX'],6*10**6],\n",
    "    # # ['CDX HY 5Y', ['RTY'],'CDX HY 5Y', ['RTY'],6*10**6],\n",
    "    # # ['CDX HY 5Y', ['RSP'],'CDX HY 5Y', ['RSP'],6*10**6],\n",
    "    # ['CDX HY 5Y', ['IWM'],'CDX HY 5Y', ['IWM'],6*10**6],\n",
    "    # ['CDX HY 5Y', ['IJH'],'CDX HY 5Y', ['IJH'],6*10**6],\n",
    "    # # ['CDX HY 5Y', ['HY Eqty'],'CDX HY 5Y', ['HY Eqty'],6*10**6],\n",
    "    \n",
    "    # # ['ITRX MAIN 5Y', ['SX5E'],'ITRX MAIN 5Y', ['SX5E'], 28*10**6],\n",
    "    # ['ITRX MAIN 5Y', ['SX5E'],'ITRX MAIN 5Y', ['SX5E'], 28*10**6],\n",
    "    # ['ITRX MAIN 5Y', ['SX5E'],'ITRX MAIN 5Y', ['SX5E','V2X'], 28*10**6],\n",
    "    # ['ITRX SNRFIN 5Y', ['SX7E'],'ITRX SNRFIN 5Y', ['SX7E'], 28*10**6],\n",
    "    # # ['ITRX XOVER 5Y', ['SX5E'],'ITRX XOVER 5Y', ['SX5E'], 6*10**6],\n",
    "    # # ['ITRX XOVER 5Y', ['SPX'],'ITRX XOVER 5Y', ['SPX'], 6*10**6],\n",
    "    # # ['CDX IG 5Y', ['ITRX MAIN 5Y'],'CDX IG 5Y', ['ITRX MAIN 5Y'], 50*10**6],\n",
    "    \n",
    "    # # ['CDX HY 5Y', ['ITRX XOVER 5Y'],'CDX HY 5Y', ['ITRX XOVER 5Y'], 8*10**6],\n",
    "    # # ['ITRX MAIN 5Y', ['ITRX XOVER 5Y'],'ITRX MAIN 5Y', ['ITRX XOVER 5Y'], 66*10**6],\n",
    "    # # ['CDX IG 5Y', ['CDX HY 5Y'],'CDX IG 5Y', ['CDX HY 5Y'], 74*10**6],\n",
    "    \n",
    "    # # ['CDX IG 5Y', ['CDX EM 5Y'],'CDX IG 5Y', ['CDX EM 5Y'], 22*10**6],\n",
    "    # # ['CDX EM 5Y', ['CDX HY 5Y'],'CDX EM 5Y', ['CDX HY 5Y'], 8*10**6],\n",
    "    # # ['ITRX MAIN 5Y', ['CDX EM 5Y'],'ITRX MAIN 5Y', ['CDX EM 5Y'], 22*10**6],\n",
    "    # # ['CDX EM 5Y', ['ITRX XOVER 5Y'],'CDX EM 5Y', ['ITRX XOVER 5Y'], 6*10**6],\n",
    "\n",
    "    # # ['CDX IG 5Y', ['SPY'],'CDX IG 5Y', ['SPY'],28*10**6],\n",
    "    # ['CDX HY 5Y', ['SPY'],'CDX HY 5Y', ['SPY'],6*10**6],\n",
    "    ['HYGH', ['LQDH'], 'HYGH', ['LQDH'], 5*10**6],\n",
    "    \n",
    "    # # ['EEM', ['EMB'], 'EEM', ['EMB'], 1*10**6],\n",
    "    # # ['CDX EM 5Y', ['EEM'], 'CDX EM 5Y', ['EEM'], 6*10**6],\n",
    "    \n",
    "]\n",
    "\n",
    "z_score_method = 'Rtn'\n",
    "# for z_score_method in ['PX','Rtn']:\n",
    "# for diff_period_list in [[1,2,3], [1], [2], [3], [4], [6], [8], [12]]:\n",
    "for diff_period_list in [[12]]:\n",
    "    \n",
    "    dict_models = {\n",
    "        1 : [\"Intraday\",252,252,'A (Intraday; 12M)'],\n",
    "        # 2 : [\"Intraday\",315,315,'B (Intraday; 15M)'],\n",
    "        # 3 : [\"Intraday\",378,378,'C (Intraday; 18M)'],\n",
    "        # 4 : [\"Intraday\",504,504,'D (Intraday; 24M)'],\n",
    "    }\n",
    "    \n",
    "    sampling_freq = '10min'\n",
    "    \n",
    "    for global_model in models_list:\n",
    "        for model_num in list(dict_models.keys()):\n",
    "            for trade_btdf_direction in ['Long','Short','Long/Short']:\n",
    "                for info in ['$pnl','$pnl/trade','SR','Hit Ratio','trades','days/trade','max DD']:\n",
    "                    globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_{info}'] = pd.DataFrame()\n",
    "                    globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_{info}'].index.name = 'Entry'\n",
    "                    globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_{info}'].columns.name = info\n",
    "    \n",
    "    fund_rates = pd.read_excel(\"Funding Rates.xlsx\")\n",
    "    fund_rates.columns = ['Date'] + list(fund_rates.columns)[1:]\n",
    "    fund_rates['Date'] = pd.to_datetime(fund_rates['Date'])\n",
    "    fund_rates = fund_rates.set_index('Date')\n",
    "    fund_rates.columns = fund_rates.columns.str.replace(\"GSCB\",\"\").str.replace(\"EQ \",\" Eqty \").str.replace(\" Funding\",\"\").str.replace(\"Net \",\"\")\n",
    "    etfs = list(set([item.split(\" \",1)[1] for item in fund_rates.columns]))\n",
    "    \n",
    "    def apply_funding(df_funding_update, variable_item):\n",
    "        if f'Long {variable_item}' in fund_rates.columns:\n",
    "            rate = fund_rates[[f'Long {variable_item}',f'Short {variable_item}']].dropna().resample(\"1min\").last().bfill().copy()\n",
    "            df_funding_update = pd.concat([df_funding_update, rate],axis=1)\n",
    "            df_funding_update = df_funding_update.dropna()\n",
    "            df_funding_update.columns = list(df_funding_update.columns)[:-2] + ['Long_Funding','Short_Funding']\n",
    "            df_funding_update['T'] = df_funding_update.index.date\n",
    "            df_funding_update['T-1'] = [np.nan] + list(df_funding_update.index[:-1].date)\n",
    "            df_funding_update['Funding_Date'] = df_funding_update.apply(lambda row: 'New Day' if row['T'] != row['T-1'] else 'Same Day', axis=1)\n",
    "            df_funding_update['Long_Funding'] = df_funding_update.apply(lambda row: row[\"Long_Funding\"] if row[\"Funding_Date\"] == \"New Day\" else 0,axis=1)\n",
    "            df_funding_update['Short_Funding'] = df_funding_update.apply(lambda row: row[\"Short_Funding\"] if row[\"Funding_Date\"] == \"New Day\" else 0,axis=1)\n",
    "            df_funding_update = df_funding_update.drop(['Funding_Date'],axis=1)\n",
    "            # df_funding_update['Funding'] = 0.5*(df_funding_update['Long_Funding'] + df_funding_update['Short_Funding'])\n",
    "            df_funding_update['T-1'] = [item.date() for item in pd.to_datetime(df_funding_update['T-1'])]\n",
    "            df_funding_update['T-1'].iloc[0] = df_funding_update['T'].iloc[0]\n",
    "            df_funding_update['Long Funding P/L'] = [item.days for item in (df_funding_update['T'] - df_funding_update['T-1'])]\n",
    "            df_funding_update['Long Funding P/L'] *= (df_funding_update['Long_Funding'] / 100) * (1/360) * abs(df_funding_update['Notional'])\n",
    "            df_funding_update['Short Funding P/L'] = [item.days for item in (df_funding_update['T'] - df_funding_update['T-1'])]\n",
    "            df_funding_update['Short Funding P/L'] *= (df_funding_update['Short_Funding'] / 100) * (1/360) * abs(df_funding_update['Notional'])\n",
    "            df_funding_update = df_funding_update.drop(['T','T-1','Long_Funding','Short_Funding'],axis=1)\n",
    "        else:\n",
    "            df_funding_update['Long Funding P/L'] = [0.0] * len(df_funding_update)\n",
    "            df_funding_update['Short Funding P/L'] = [0.0] * len(df_funding_update)\n",
    "    \n",
    "        return df_funding_update.copy()\n",
    "    \n",
    "    # bbg_px = pd.read_excel(\"10min data with EUv10.xlsx\", index_col=0, parse_dates=True)\n",
    "    # bbg_px = pd.read_excel(\"10min data with EUv11.xlsx\", index_col=0, parse_dates=True)\n",
    "    # bbg_px = pd.read_excel(\"10min data with EUv12.xlsx\", index_col=0, parse_dates=True)\n",
    "    bbg_px = pd.read_parquet(\"10min data with EUv12.parquet\")\n",
    "    \n",
    "    if z_score_method == \"PX\":\n",
    "        zscore_calc_df = bbg_px.copy()\n",
    "    elif z_score_method == \"Rtn\":\n",
    "        # zscore_calc_df = pd.read_parquet(\"1min ER series v3.parquet\")   \n",
    "        # zscore_calc_df = pd.read_parquet(\"1min ER series v4.parquet\")  \n",
    "        zscore_calc_df = pd.read_parquet(\"1min ER series v5.parquet\")  \n",
    "        # zscore_calc_df = pd.read_parquet(\"Intraday 1min ER series.parquet\")\n",
    "    \n",
    "    for global_model in models_list:\n",
    "        for model_num in list(dict_models.keys()):  \n",
    "    \n",
    "            # global_model = models_list[0]\n",
    "            # model_num = list(dict_models.keys())[0]\n",
    "            \n",
    "            model_Y = global_model[0]\n",
    "            model_X = global_model[1]\n",
    "            zscore_Y = global_model[2]\n",
    "            zscore_X = global_model[3]\n",
    "            backtest_start_date = pd.to_datetime('2017-03-01')\n",
    "            notional_to_use = global_model[4]\n",
    "            \n",
    "            zscore_vars = [model_Y, zscore_Y] + model_X + zscore_X\n",
    "            \n",
    "            zscore_vars = list(set(zscore_vars))\n",
    "            zscore_vars_start_time = max([dict_map[item][1] for item in zscore_vars])\n",
    "            zscore_vars_end_time = min([dict_map[item][2] for item in zscore_vars])\n",
    "            \n",
    "            ################################## Beta Calculation\n",
    "            if len(model_X) == 1:\n",
    "                er_Y = f'ER {model_Y}'\n",
    "                er_X = f'ER {model_X[0]}'\n",
    "                er_data = pd.read_csv(\"All ER.csv\")\n",
    "                er_data.columns = ['Date'] + list(er_data.columns)[1:]\n",
    "                er_data['Date'] = pd.to_datetime(er_data['Date'])\n",
    "                er_data = er_data.set_index('Date')\n",
    "                er_data = er_data.sort_index()\n",
    "                beta = er_data[[er_Y, er_X]].dropna()\n",
    "                beta = beta.resample('W').last()\n",
    "                beta = np.log(beta)\n",
    "                beta = beta.diff().dropna()\n",
    "                beta['Beta1'] = [np.nan] * len(beta)\n",
    "                beta['Beta2'] = [np.nan] * len(beta)\n",
    "                \n",
    "                for i in range(len(beta)-24+1):\n",
    "                    reg_X = beta[er_X].iloc[i:i+24]\n",
    "                    reg_Y = beta[er_Y].iloc[i:i+24]\n",
    "                    model = sm.OLS(reg_Y, sm.add_constant(reg_X)).fit() \n",
    "                    beta.iloc[i+23,2] = model.params.iloc[1]\n",
    "                \n",
    "                    model = sm.OLS(reg_X, sm.add_constant(reg_Y)).fit() \n",
    "                    beta.iloc[i+23,3] = model.params.iloc[1]\n",
    "                \n",
    "                beta['Beta1'] = beta['Beta1'].rolling(104).mean()\n",
    "                beta['Beta2'] = beta['Beta2'].rolling(104).mean()\n",
    "                beta['Beta'] = 0.5*(beta['Beta1'] + 1/ beta['Beta2'])\n",
    "                beta = beta[['Beta']].dropna()\n",
    "                # beta = pd.read_excel(\"igspx_beta_1ymodel.xlsx\", index_col=0, parse_dates=True)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                b1 = pd.read_csv(\"All Basis Trade Betas.csv\")\n",
    "                b1.columns = ['Date'] + list(b1.columns)[1:]\n",
    "                b1 = b1.set_index('Date')\n",
    "                beta = b1[[f'{model_Y}_{model_X[0]}_{model_X[1]}']]\n",
    "                beta.columns = ['Beta']\n",
    "                beta['Coef1'] = beta['Beta'].apply(lambda x: eval(x)[0])\n",
    "                beta['Coef2'] = beta['Beta'].apply(lambda x: eval(x)[1])\n",
    "                beta.index = pd.to_datetime(beta.index)\n",
    "                \n",
    "            beta = beta.resample(\"1min\").first().ffill()\n",
    "            \n",
    "            ################################## BBG DataFile Intraday\n",
    "            # df = pd.read_excel(\"10min data with EUv7.xlsx\")\n",
    "            # df['Date'] = pd.to_datetime(df['Date'])\n",
    "            # df = df.set_index('Date')\n",
    "            # df = df.sort_index()\n",
    "            df = zscore_calc_df.copy()\n",
    "            \n",
    "            zscore_df = df[zscore_vars].between_time(zscore_vars_start_time, zscore_vars_end_time).dropna().copy()\n",
    "            zscore_df = zscore_df.resample(\"10min\",offset=\"5min\").last().dropna().copy()\n",
    "            zscore_df = zscore_df.between_time(zscore_vars_start_time, zscore_vars_end_time).dropna().copy()\n",
    "            bbg_datafile = zscore_df.copy()\n",
    "            \n",
    "            sampling_multiplier = len(set(list(bbg_datafile.index.time)))\n",
    "            \n",
    "            ################################## ZScore Calculation Start : Convert Sprd to PX series\n",
    "            \n",
    "            df = pd.read_excel(\"All DQ Duration.xlsx\")\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df = df.set_index('Date')\n",
    "            df = df.sort_index()\n",
    "            df.columns = df.columns.str.replace(\" Dur\",\"\")\n",
    "            df = df.resample(\"1min\").first().ffill().dropna()\n",
    "            dq_dur = df.copy()\n",
    "            \n",
    "            zscore_df1 = zscore_df.copy()\n",
    "    \n",
    "            if z_score_method == \"PX\":\n",
    "                for col in zscore_df1.columns:\n",
    "                    if col in dq_dur.columns:\n",
    "                        zscore_df1[f'{col} Dur'] = dq_dur[col]\n",
    "                        zscore_df1[f'{col} Dur'] = zscore_df1[f'{col} Dur'].shift(1)\n",
    "                        zscore_df1[f'Diff {col}'] = zscore_df1[col].diff()\n",
    "                        zscore_df1 = zscore_df1.dropna()\n",
    "                        zscore_df1[f'{col} Daily PX Change'] = -1 * zscore_df1[f'Diff {col}'] * zscore_df1[f'{col} Dur'] *10**(-4)\n",
    "                        zscore_df1[f'{col} Sum PX'] = zscore_df1[f'{col} Daily PX Change'].cumsum()\n",
    "                        zscore_df1[col] = zscore_df1[f'{col} Sum PX']\n",
    "                        zscore_df1 = zscore_df1[zscore_df.columns].copy()\n",
    "            \n",
    "            ################################## ZScore Calculation: Differencing and converting to ZScores\n",
    "            \n",
    "            zscore_df = zscore_df1[zscore_df1.index >= backtest_start_date].copy()\n",
    "            \n",
    "            col_list = zscore_df.columns\n",
    "            for period in diff_period_list:\n",
    "                for col in col_list:\n",
    "                    zscore_df[f'{col}_{period}W'] = zscore_df[col].diff(sampling_multiplier*5*period)\n",
    "                    # zscore_df[f'{col}_{period}W'] = zscore_df[col].diff(sampling_multiplier*period)  ##### Daily\n",
    "            \n",
    "            model_lookback = sampling_multiplier*dict_models[model_num][1]\n",
    "            model_lookback_res = sampling_multiplier*dict_models[model_num][2]\n",
    "            zscore_df = zscore_df.dropna().copy()\n",
    "            zscore_df2 = zscore_df.copy()\n",
    "    \n",
    "            for period in diff_period_list:\n",
    "                for i in range(len(zscore_df) - model_lookback + 1):\n",
    "            \n",
    "                    reg_Y = zscore_df[[f'{zscore_Y}_{period}W']].iloc[i:i+model_lookback]\n",
    "                    reg_X = zscore_df[[item + f\"_{period}W\" for item in zscore_X]].iloc[i:i+model_lookback]\n",
    "    \n",
    "                    model = sm.OLS(reg_Y,sm.add_constant(reg_X)).fit()\n",
    "                    x = (model.resid - model.resid.rolling(model_lookback_res).mean())/model.resid.rolling(model_lookback_res).std()\n",
    "                    zscore_df.loc[zscore_df.index[i+model_lookback-1],f'{period}W_ZScore'] = x.iloc[-1]\n",
    "    \n",
    "            zscore_df['Avg. ZScore'] = zscore_df[[col for col in zscore_df.columns if col.endswith(\"_ZScore\")]].mean(axis=1)\n",
    "            zscore_df = zscore_df[['Avg. ZScore']]\n",
    "            bt_df = pd.concat([bbg_datafile[[model_Y] + model_X],zscore_df],axis=1).dropna()   \n",
    "            \n",
    "            #############################################\n",
    "    \n",
    "            if z_score_method == \"Rtn\":\n",
    "                bbg_data = bbg_px.copy()\n",
    "                bbg_data = bbg_data[[model_Y] + model_X].dropna().copy()\n",
    "                bbg_data = bbg_data.resample(\"10min\", offset=\"5min\").last().ffill().copy()\n",
    "                bbg_data = bbg_data[bbg_data.index.isin(bt_df.index)]\n",
    "                for col in bbg_data.columns:\n",
    "                    bt_df[col] = bbg_data[col]\n",
    "                \n",
    "            ############################# If dur > 0 => trades on sprd ; if dur = 0 => cdx trades on px ; if dur = -1 => eq. product trades on px\n",
    "            for col in bt_df.columns:\n",
    "                if col != \"Avg. ZScore\":\n",
    "                    if col in dq_dur.columns:\n",
    "                        bt_df[f'{col} Dur'] = dq_dur[dq_dur.index.isin(bt_df.index)][col]\n",
    "                    elif dict_map[col][0] == 'CDX':\n",
    "                        bt_df[f'{col} Dur'] = [0.0] * len(bt_df)\n",
    "                    elif dict_map[col][0] == 'Eq':\n",
    "                        bt_df[f'{col} Dur'] = [-1.0] * len(bt_df)\n",
    "            bt_df['volume'] = [0.0] * len(bt_df)\n",
    "            \n",
    "            bt_df = bt_df[bt_df.index >= pd.to_datetime(\"2021-07-01\")].dropna()\n",
    "            bt_df = bt_df[bt_df.index <= pd.to_datetime(\"2025-04-26\")].dropna()\n",
    "            \n",
    "            ############################# Backtrader dfs\n",
    "            bt_df = pd.concat([bt_df,beta],axis=1).dropna()\n",
    "            bt_df.columns = bt_df.columns.str.replace(\"Beta\",\"Notional\")\n",
    "            \n",
    "            if len(model_X) == 1:\n",
    "                dfy = bt_df[[model_Y,f'{model_Y} Dur','Avg. ZScore','Notional','volume']].dropna().copy()\n",
    "                dfy.columns = dfy.columns.str.replace(\"Avg. ZScore\",\"Signal\").str.replace(f'{model_Y} Dur','Dur').str.replace(model_Y,\"close\")\n",
    "                dfy['Notional'] = notional_to_use\n",
    "                \n",
    "                dfx = bt_df[[model_X[0],f'{model_X[0]} Dur','Avg. ZScore','Notional','volume']].dropna().copy()\n",
    "                dfx.columns = dfx.columns.str.replace(\"Avg. ZScore\",\"Signal\").str.replace(f'{model_X[0]} Dur','Dur').str.replace(model_X[0],\"close\")\n",
    "                dfx['Notional'] *= notional_to_use\n",
    "                dfx['Signal'] *= -1    \n",
    "            \n",
    "                dfy = apply_funding(dfy.copy(), model_Y)\n",
    "                dfx = apply_funding(dfx.copy(), model_X[0])\n",
    "            \n",
    "            if len(model_X) == 2:\n",
    "                \n",
    "                dfy = bt_df[[model_Y,f'{model_Y} Dur','Avg. ZScore','Notional','volume']].dropna().copy()\n",
    "                dfy.columns = dfy.columns.str.replace(\"Avg. ZScore\",\"Signal\").str.replace(f'{model_Y} Dur','Dur').str.replace(model_Y,\"close\")\n",
    "                dfy['Notional'] = notional_to_use\n",
    "                \n",
    "                dfx = bt_df[[model_X[0],f'{model_X[0]} Dur','Avg. ZScore','Notional','volume']].dropna().copy()\n",
    "                dfx.columns = dfx.columns.str.replace(\"Avg. ZScore\",\"Signal\").str.replace(f'{model_X[0]} Dur','Dur').str.replace(model_X[0],\"close\")\n",
    "                dfx['Notional'] = notional_to_use * bt_df['Coef1']\n",
    "                dfx['Signal'] *= -1   ############################ in basis only hyg px we sell when we buy the residuals so only this will be inverted\n",
    "                \n",
    "                dfx1 = bt_df[[model_X[1],f'{model_X[1]} Dur','Avg. ZScore','Notional','volume']].dropna().copy()\n",
    "                dfx1.columns = dfx1.columns.str.replace(\"Avg. ZScore\",\"Signal\").str.replace(f'{model_X[1]} Dur','Dur').str.replace(model_X[1],\"close\")\n",
    "                dfx1['Notional'] = notional_to_use * bt_df['Coef2']\n",
    "            \n",
    "                dfy = apply_funding(dfy.copy(), model_Y)\n",
    "                dfx = apply_funding(dfx.copy(), model_X[0])\n",
    "                dfx1 = apply_funding(dfx1.copy(), model_X[1])\n",
    "            \n",
    "            \n",
    "            class MyData(bt.feeds.PandasData):\n",
    "                lines = ('signal', 'notional', 'dur', 'long_funding', 'short_funding')\n",
    "                params = (('signal', 'Signal'), ('notional', 'Notional'), \n",
    "                          ('dur', 'Dur'), ('long_funding', 'Long Funding P/L'), ('short_funding', 'Short Funding P/L'))\n",
    "            \n",
    "            class FixedComm(bt.CommInfoBase):\n",
    "                params = (('commission', 0), ('stocklike', True), ('commtype', bt.CommInfoBase.COMM_FIXED),)\n",
    "                def _getcommission(self, size, price, pseudoexec):\n",
    "                    return self.p.commission\n",
    "            \n",
    "            class TStrategy(bt.Strategy):\n",
    "                params = dict(cheat_on_close=True, entry_zscore = 0, exit_zscore = 0, carry = 0, product = 'Untitled')\n",
    "                \n",
    "                def __init__(self):\n",
    "                    self.portfolio_values = []\n",
    "                    self.entry_date = None\n",
    "                    self.daily_pnl = []\n",
    "                    self.roll_trades = []\n",
    "                    self.carry = []\n",
    "                    self.roll_carry = []\n",
    "                    \n",
    "                    self.funding = []\n",
    "                    self.funding_carry = []\n",
    "                    self.funding_direction = None\n",
    "                    self.entry_bar_funding = None\n",
    "                    \n",
    "                    self.trade_direction = []\n",
    "                    \n",
    "                    self.scatter_plot_trade_pnl = []\n",
    "                    self.scatter_plot_trade_init_len = None\n",
    "                    \n",
    "                    self.carry_direction = 0\n",
    "                    self.logs = []\n",
    "            \n",
    "                def log(self, txt):\n",
    "                    dt = self.datas[0].datetime.datetime(0)\n",
    "                    print(f'{dt} - {txt}')\n",
    "                    self.logs.append([dt.isoformat(), txt])\n",
    "            \n",
    "                def notify_trade(self, trade):            \n",
    "                    if trade.isclosed:            \n",
    "                        current_date = self.datas[0].datetime.datetime(-1)\n",
    "                        \n",
    "                        self.trade_direction.append((current_date, self.funding_direction if self.p.product == model_Y else None)) \n",
    "                        #### Y determines the long/short direction\n",
    "                        \n",
    "                        \n",
    "                        ######################################## Calculating carry for all trades\n",
    "                        self.daily_pnl.append((current_date, trade.pnlcomm))\n",
    "            \n",
    "                        if self.carry_direction > 0 : \n",
    "                            self.carry.append((current_date, (current_date.date()-self.entry_date.\\\n",
    "                                                              date()).days*(1/360)*self.p.carry*(1/100)*self.datas[0].notional[0]))\n",
    "                        elif self.carry_direction < 0 :\n",
    "                            self.carry.append((current_date, -1*(current_date.date()-self.entry_date.\\\n",
    "                                                             date()).days*(1/360)*self.p.carry*(1/100)*self.datas[0].notional[0]))\n",
    "                        \n",
    "                        ######################################## Calculating funding for all trades\n",
    "                        bars_active = len(self) - self.entry_bar_funding - 1\n",
    "                        \n",
    "                        if self.funding_direction == \"Long\":\n",
    "                            values = [self.datas[0].long_funding[-i] for i in range(bars_active)]\n",
    "                            rolling_sum = -1*sum(values)  ############ We pay the long funding\n",
    "                        \n",
    "                        elif self.funding_direction == \"Short\":\n",
    "                            values = [self.datas[0].short_funding[-i] for i in range(bars_active)]\n",
    "                            rolling_sum = sum(values)  ############ We earn the short funding\n",
    "                            \n",
    "                        self.funding.append((current_date, rolling_sum))\n",
    "            \n",
    "                        \n",
    "                        p1 = [datetime(current_date.year, 3, 20), datetime(current_date.year, 3, 30)]\n",
    "                        p2 = [datetime(current_date.year, 9, 20), datetime(current_date.year, 9, 30)]\n",
    "                        p3 = [datetime(current_date.year+1, 3, 20), datetime(current_date.year+1, 3, 30)]\n",
    "                        p4 = [datetime(current_date.year-1, 9, 20), datetime(current_date.year-1, 9, 30)]\n",
    "                        periods = [p1, p2, p3, p4]\n",
    "                        \n",
    "                        ######################################## Calculating carry for roll trades separately\n",
    "                        \n",
    "                        for i in range(len(periods)):\n",
    "                            p = periods[i]\n",
    "                            if ((self.entry_date <= p[1]) and (p[0] <= current_date)):\n",
    "                                self.roll_trades.append((current_date, trade.pnlcomm))\n",
    "                                if self.carry_direction > 0:\n",
    "                                    self.roll_carry.append((current_date, (current_date.date()-self.entry_date.\\\n",
    "                                                                   date()).days*(1/360)*self.p.carry*(1/100)*self.datas[0].notional[0]))\n",
    "                                elif self.carry_direction < 0:\n",
    "                                    self.roll_carry.append((current_date, -1*(current_date.date()-self.entry_date.\\\n",
    "                                                                  date()).days*(1/360)*self.p.carry*(1/100)*self.datas[0].notional[0]))\n",
    "            \n",
    "                                self.funding_carry.append((current_date, rolling_sum))\n",
    "                                \n",
    "                                break\n",
    "                        \n",
    "                        ################################################# All trades\n",
    "                        \n",
    "                        # self.log(f'Gross P/L: {trade.pnl:.2f}, Net P/L: {trade.pnlcomm:.2f}, Funding P/L: {rolling_sum:.2f}')        \n",
    "                        self.carry_direction = 0\n",
    "            \n",
    "                # def notify_order(self, order):\n",
    "                #     if order.status in [order.Completed]:\n",
    "                #         if order.isbuy():\n",
    "                #             self.log(f'BUY EXECUTED, PX: {order.executed.price:.4f}, Qty: {order.executed.size:.2f}, Comm: {order.executed.comm}')\n",
    "                #         else:\n",
    "                #             self.log(f'SELL EXECUTED, PX: {order.executed.price:.4f}, Qty: {order.executed.size:.2f}, Comm: {order.executed.comm}')\n",
    "            \n",
    "                def next(self):\n",
    "                    self.broker.set_coc(self.p.cheat_on_close)\n",
    "                    # val = None\n",
    "                    self.portfolio_values.append((self.datas[0].datetime.datetime(0), self.broker.getvalue()))\n",
    "                    \n",
    "                    z = self.datas[0].signal[0]\n",
    "                    px = self.datas[0].close[0]        \n",
    "                    pos = self.getposition(self.datas[0]).size\n",
    "            \n",
    "                    # self.log(f'PX: {px}, ZScore: {z:.3f}, Notional: {self.datas[0].notional[0]:.0f}, Dur: {self.datas[0].dur[0]:.4f} '\n",
    "                    #          f'Pos: {pos:.2f}, Long Funding $: {self.datas[0].long_funding[0]:.2f}, Short Funding $: {self.datas[0].short_funding[0]:.2f} '\n",
    "                    #          f'Eqty (000): {(self.broker.getvalue()-1e12)*10**(-3):.2f}')\n",
    "                    \n",
    "                    if pos == 0:                \n",
    "                        if z < -self.p.entry_zscore:\n",
    "                            self.scatter_plot_trade_init_len = len(self)\n",
    "                            self.entry_date = self.datas[0].datetime.datetime(0)\n",
    "            \n",
    "                            if self.datas[0].dur[0] == -1:\n",
    "                                self.buy(data = self.data, size = self.datas[0].notional[0]/px)\n",
    "                            elif self.datas[0].dur[0] == 0.0:\n",
    "                                self.buy(data=self.datas[0], size = (self.datas[0].notional[0] / 100))\n",
    "                            elif self.datas[0].dur[0] > 0.0:\n",
    "                                self.sell(data=self.data, size = (self.datas[0].notional[0])*10**(-4)*self.datas[0].dur[0])\n",
    "            \n",
    "                            self.carry_direction = 1\n",
    "                            self.entry_bar_funding = len(self)\n",
    "                            self.funding_direction = \"Long\"\n",
    "            \n",
    "                        elif z > self.p.entry_zscore:\n",
    "                            self.scatter_plot_trade_init_len = len(self)\n",
    "                            self.entry_date = self.datas[0].datetime.datetime(0)\n",
    "            \n",
    "                            if self.datas[0].dur[0] == -1:\n",
    "                                self.sell(data = self.data, size = self.datas[0].notional[0]/px)\n",
    "                            elif self.datas[0].dur[0] == 0.0:\n",
    "                                self.sell(data=self.datas[0], size = (self.datas[0].notional[0] / 100))\n",
    "                            elif self.datas[0].dur[0] > 0.0:\n",
    "                                self.buy(data=self.data, size = (self.datas[0].notional[0])*10**(-4)*self.datas[0].dur[0])\n",
    "            \n",
    "                            self.carry_direction = -1\n",
    "                            self.entry_bar_funding = len(self)\n",
    "                            self.funding_direction = \"Short\"\n",
    "                            \n",
    "                    else:\n",
    "                            if self.datas[0].dur[0] <= 0.0: ######## Equity & CDX HY\n",
    "                                if ((pos > 0 and z > -self.p.exit_zscore) or (pos < 0 and z < self.p.exit_zscore)):\n",
    "                                    self.close(data=self.datas[0])\n",
    "                                    self.scatter_plot_trade_pnl.append((self.datas[0].datetime.\\\n",
    "                                                        datetime(0), len(self) - self.scatter_plot_trade_init_len))\n",
    "                            \n",
    "                            elif self.datas[0].dur[0] > 0.0: ######## CDX IG\n",
    "                                if ((pos < 0 and z > -self.p.exit_zscore) or (pos > 0 and z < self.p.exit_zscore)):\n",
    "                                    self.close(data=self.datas[0])\n",
    "                                    self.scatter_plot_trade_pnl.append((self.datas[0].datetime.\\\n",
    "                                                        datetime(0), len(self) - self.scatter_plot_trade_init_len))\n",
    "            \n",
    "            \n",
    "                # def stop(self):\n",
    "                #     # with open(f'{self.p.product}.csv', 'w', newline='') as f:\n",
    "                #     with open(f'backtrader_log_{str(datetime.now().time()).replace(\":\",\"_\")}.csv', 'w', newline='') as f:\n",
    "                #         writer = csv.writer(f)\n",
    "                #         writer.writerow(['Date','Message'])\n",
    "                #         writer.writerows(self.logs)\n",
    "            \n",
    "            for strategy_zscore_exit in [0.0, 0.25, 0.5, 0.75, 1.0]:\n",
    "                for strategy_zscore_entry in [0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0]:\n",
    "                    if strategy_zscore_entry > strategy_zscore_exit:\n",
    "            \n",
    "                        cerebro1 = bt.Cerebro()\n",
    "                        cerebro1.addstrategy(TStrategy, cheat_on_close=True, entry_zscore = strategy_zscore_entry, exit_zscore = strategy_zscore_exit,\\\n",
    "                                             carry = dict_map[model_Y][3], product = model_Y)\n",
    "                        \n",
    "                        cerebro1.broker.setcash(1e12)\n",
    "                        feed1 = MyData(dataname=dfy.copy(), timeframe=bt.TimeFrame.Minutes)\n",
    "                        cerebro1.adddata(feed1)\n",
    "                        cerebro1.broker.set_slippage_fixed(fixed=dict_map[model_Y][5], slip_open=True, slip_limit=True, slip_match=True, slip_out=True)\n",
    "                        cerebro1.broker.setcommission(margin=0.00001, mult=1)\n",
    "                        cerebro1.broker.addcommissioninfo(FixedComm(commission=dict_map[model_Y][6]))\n",
    "                        cerebro1.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trade_analyzer')\n",
    "                        results1 = cerebro1.run()\n",
    "                        \n",
    "                        cerebro2 = bt.Cerebro()\n",
    "                        cerebro2.addstrategy(TStrategy, cheat_on_close=True, entry_zscore = strategy_zscore_entry, exit_zscore = strategy_zscore_exit,\\\n",
    "                                             carry = dict_map[model_X[0]][3], product = model_X[0])\n",
    "                        cerebro2.broker.setcash(1e12)\n",
    "                        feed2 = MyData(dataname=dfx.copy(), timeframe=bt.TimeFrame.Minutes)\n",
    "                        cerebro2.adddata(feed2)\n",
    "                        cerebro2.broker.set_slippage_fixed(fixed=dict_map[model_X[0]][5], slip_open=True, slip_limit=True, slip_match=True, slip_out=True)\n",
    "                        cerebro2.broker.setcommission(margin=0.00001, mult=1)\n",
    "                        cerebro1.broker.addcommissioninfo(FixedComm(commission=dict_map[model_X[0]][6]))\n",
    "                        cerebro2.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trade_analyzer')\n",
    "                        results2 = cerebro2.run()\n",
    "            \n",
    "                        if len(model_X) == 2:\n",
    "                            cerebro3 = bt.Cerebro()\n",
    "                            cerebro3.addstrategy(TStrategy, cheat_on_close=True, entry_zscore = strategy_zscore_entry, \\\n",
    "                                                 exit_zscore = strategy_zscore_exit,\\\n",
    "                                                 carry = dict_map[model_X[1]][3], product = model_X[1])\n",
    "                            cerebro3.broker.setcash(1e12)\n",
    "                            feed3 = MyData(dataname=dfx1.copy(), timeframe=bt.TimeFrame.Minutes)\n",
    "                            cerebro3.adddata(feed3)\n",
    "                            cerebro3.broker.set_slippage_fixed(fixed=dict_map[model_X[1]][5], slip_open=True, slip_limit=True, \\\n",
    "                                                               slip_match=True, slip_out=True)\n",
    "                            cerebro3.broker.setcommission(margin=0.00001, mult=1)\n",
    "                            cerebro1.broker.addcommissioninfo(FixedComm(commission=dict_map[model_X[1]][6]))\n",
    "                            cerebro3.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trade_analyzer')\n",
    "                            results3 = cerebro3.run()\n",
    "            \n",
    "                        \n",
    "                        strat1 = results1[0]\n",
    "                        dates1, values1 = zip(*strat1.portfolio_values)\n",
    "                        \n",
    "                        strat2 = results2[0]\n",
    "                        dates2, values2 = zip(*strat2.portfolio_values)\n",
    "            \n",
    "                        if len(model_X) == 2:\n",
    "                            strat3 = results3[0]\n",
    "                            dates3, values3 = zip(*strat3.portfolio_values)\n",
    "                        \n",
    "                        # clear_output(wait=False)\n",
    "                        \n",
    "                        \n",
    "                        #############################################################################################################################\n",
    "                        \n",
    "                        ############################################### Basic PX based P/L\n",
    "                        try:\n",
    "                            dates3, values3 = zip(*strat1.daily_pnl)\n",
    "                            d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                            dates3, values3 = zip(*strat2.daily_pnl)\n",
    "                            d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                \n",
    "                            if len(model_X) == 1:\n",
    "                                d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                                d5['Daily P/L'] = d5['CDX'] + d5['SPX']\n",
    "                            \n",
    "                            elif len(model_X) == 2:\n",
    "                                dates3, values3 = zip(*strat3.daily_pnl)\n",
    "                                d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                d5['Daily P/L'] = d5['CDX'] + d5['SPX'] + d5['SPX2']\n",
    "                \n",
    "                            d5 = round(d5[['Daily P/L']].astype(float),2)\n",
    "                            daily_pnl = d5.copy()\n",
    "                \n",
    "                            ############################################### Removing Roll basic PX P/L\n",
    "                            try:\n",
    "                                dates3, values3 = zip(*strat1.roll_trades)\n",
    "                                d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                                dates3, values3 = zip(*strat2.roll_trades)\n",
    "                                d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                \n",
    "                                if len(model_X) == 1:\n",
    "                                    d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                                    d5['Roll P/L'] = d5['CDX'] + d5['SPX']\n",
    "                                \n",
    "                                elif len(model_X) == 2:\n",
    "                                    dates3, values3 = zip(*strat3.roll_trades)\n",
    "                                    d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                    d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                    d5['Roll P/L'] = d5['CDX'] + d5['SPX'] + d5['SPX2']\n",
    "                \n",
    "                                d5 = -1*round(d5[['Roll P/L']].astype(float),2)\n",
    "                                roll_trades = d5.copy()\n",
    "                            except Exception as e:\n",
    "                                roll_trades = pd.DataFrame()\n",
    "                \n",
    "                            ############################################### Adding all trades carry\n",
    "                            try:\n",
    "                                dates3, values3 = zip(*strat1.carry)\n",
    "                                d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                                dates3, values3 = zip(*strat2.carry)\n",
    "                                d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                \n",
    "                                if len(model_X) == 1:\n",
    "                                    d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                                    d5['CDX Carry'] = d5['CDX'] + d5['SPX']\n",
    "                                    \n",
    "                                elif len(model_X) == 2:\n",
    "                                    dates3, values3 = zip(*strat3.carry)\n",
    "                                    d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                    d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                    d5['CDX Carry'] = d5['CDX'] + d5['SPX'] + d5['SPX2']\n",
    "                \n",
    "                                d5 = round(d5[['CDX Carry']].astype(float),2)\n",
    "                                carry = d5.copy()\n",
    "                            except Exception as e:\n",
    "                                carry = pd.DataFrame()\n",
    "                            \n",
    "                            ############################################### Remove carry of roll trades\n",
    "                            \n",
    "                            try:\n",
    "                                dates3, values3 = zip(*strat1.roll_carry)\n",
    "                                d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                                dates3, values3 = zip(*strat2.roll_carry)\n",
    "                                d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                \n",
    "                                if len(model_X) == 1:\n",
    "                                    d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                                    d5['CDX Roll Carry'] = d5['CDX'] + d5['SPX']\n",
    "                \n",
    "                                elif len(model_X) == 2:\n",
    "                                    dates3, values3 = zip(*strat3.roll_carry)\n",
    "                                    d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                    d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                    d5['CDX Roll Carry'] = d5['CDX'] + d5['SPX'] + d5['SPX2']\n",
    "                \n",
    "                                d5 = -1*round(d5[['CDX Roll Carry']].astype(float),2)\n",
    "                                roll_carry = d5.copy()\n",
    "                            except Exception as e:\n",
    "                                roll_carry = pd.DataFrame()\n",
    "                \n",
    "                            ############################################### Add funding of all trades\n",
    "                            \n",
    "                            try:\n",
    "                                dates3, values3 = zip(*strat1.funding)\n",
    "                                d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                                dates3, values3 = zip(*strat2.funding)\n",
    "                                d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                \n",
    "                                if len(model_X) == 1:\n",
    "                                    d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                                    d5['Funding'] = d5['CDX'] + d5['SPX']\n",
    "                \n",
    "                                elif len(model_X) == 2:\n",
    "                                    dates3, values3 = zip(*strat3.funding)\n",
    "                                    d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                    d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                    d5['Funding'] = d5['CDX'] + d5['SPX'] + d5['SPX2']\n",
    "                \n",
    "                                d5 = round(d5[['Funding']].astype(float),2)\n",
    "                                funding = d5.copy()\n",
    "                            except Exception as e:\n",
    "                                funding = pd.DataFrame()\n",
    "                                \n",
    "                            ############################################### Remove funding of carry trades\n",
    "                            \n",
    "                            try:\n",
    "                                dates3, values3 = zip(*strat1.funding_carry)\n",
    "                                d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                                dates3, values3 = zip(*strat2.funding_carry)\n",
    "                                d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                \n",
    "                                if len(model_X) == 1:\n",
    "                                    d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                                    d5['funding_carry'] = d5['CDX'] + d5['SPX']\n",
    "                \n",
    "                                elif len(model_X) == 2:\n",
    "                                    dates3, values3 = zip(*strat3.funding_carry)\n",
    "                                    d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                    d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                    d5['funding_carry'] = d5['CDX'] + d5['SPX'] + d5['SPX2']\n",
    "                \n",
    "                                d5 = -1*round(d5[['funding_carry']].astype(float),2)\n",
    "                                funding_carry = d5.copy()\n",
    "                            except Exception as e:\n",
    "                                funding_carry = pd.DataFrame()\n",
    "                \n",
    "                            #############################################################################################################################\n",
    "                \n",
    "                            dates3, values3 = zip(*strat1.trade_direction)\n",
    "                            long_short_ind = pd.DataFrame({ 'Ind':list(values3)}, index = list(dates3))\n",
    "                            \n",
    "                            bt_df = pd.concat([dfy[['volume']], daily_pnl, roll_trades, carry, roll_carry, funding, funding_carry],axis=1)\n",
    "                            bt_df = bt_df.iloc[:,1:]\n",
    "                            bt_df = bt_df.fillna(0.0)\n",
    "    \n",
    "    \n",
    "                            ####### Keep commented to adjust for funding; if no funding then remove the hash    \n",
    "                            ####### these are when want to tally with old model outputs                        \n",
    "                            # bt_df['Funding'] = [0.0] * len(bt_df)\n",
    "                            # bt_df['funding_carry'] = [0.0] * len(bt_df)\n",
    "                            \n",
    "                            bt_df_backup = bt_df.copy()\n",
    "                            \n",
    "                            for trade_btdf_direction in ['Long/Short']: #'Long','Short',\n",
    "                                bt_df = bt_df_backup.copy()\n",
    "                                \n",
    "                                trade_check = None if trade_btdf_direction == 'Long/Short' else trade_btdf_direction\n",
    "                                \n",
    "                                bt_df['Sum'] = bt_df.sum(axis=1)\n",
    "                                x = pd.concat([bt_df, long_short_ind],axis=1).copy()\n",
    "                                x = x[x['Ind']!=trade_check].drop(\"Ind\",axis=1).copy()   ###### Use not equal operator\n",
    "                                x = pd.concat([dfy[['volume']],x],axis=1).copy()\n",
    "                                x = x.iloc[:,1:].fillna(0.0)\n",
    "                                bt_df = x.copy()\n",
    "                                trade_num = len(bt_df[bt_df['Sum']!=0])\n",
    "                                bt_df = bt_df.drop(\"Sum\",axis=1)\n",
    "                \n",
    "                \n",
    "                                ###########################################################################################################################\n",
    "                \n",
    "                                sr = bt_df.copy()\n",
    "                                sr['Sum'] = sr.sum(axis=1)\n",
    "                                sr = sr[['Sum']]\n",
    "                                sr = sr.cumsum().resample(\"D\").last().dropna().copy()\n",
    "                                sr += 10**7\n",
    "                                sr = sr.pct_change()\n",
    "                                sr = round((252**0.5*sr.mean()/sr.std()).iloc[0],3)\n",
    "                                \n",
    "                                globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_$pnl'].\\\n",
    "                                loc[strategy_zscore_entry,strategy_zscore_exit] = round(bt_df.sum().sum(),0)\n",
    "                                globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_$pnl/trade'].\\\n",
    "                                loc[strategy_zscore_entry,strategy_zscore_exit] = round(bt_df.sum().sum()/trade_num,0)\n",
    "                                globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_SR'].\\\n",
    "                                loc[strategy_zscore_entry,strategy_zscore_exit] = round(sr,2)\n",
    "                                globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_trades'].\\\n",
    "                                loc[strategy_zscore_entry,strategy_zscore_exit] = trade_num\n",
    "                \n",
    "                                bt_df['Sum'] = bt_df.sum(axis=1)\n",
    "                                pos = len(bt_df[bt_df['Sum']>0])\n",
    "                                neg = len(bt_df[bt_df['Sum']<0])\n",
    "                                try:\n",
    "                                    hit = round((pos/(pos+neg))*100,0)\n",
    "                                except:\n",
    "                                    hit = 0\n",
    "                                globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_Hit Ratio'].\\\n",
    "                                loc[strategy_zscore_entry,strategy_zscore_exit] = round(hit,0)\n",
    "                    \n",
    "                                max_dd = bt_df[['Sum']].cumsum().copy()\n",
    "                                max_dd['Roll Max'] = max_dd[['Sum']].rolling(window=10000000, min_periods=1).max()\n",
    "                                max_dd['Diff'] = abs(max_dd['Roll Max'] - max_dd['Sum'])\n",
    "                                globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_max DD'].\\\n",
    "                                loc[strategy_zscore_entry,strategy_zscore_exit] = round(-1*max_dd['Diff'].max(),0)\n",
    "                                \n",
    "                                ############################### Plots\n",
    "                                \n",
    "                                dates3, values3 = zip(*strat1.scatter_plot_trade_pnl)\n",
    "                                d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                                dates3, values3 = zip(*strat2.scatter_plot_trade_pnl)\n",
    "                                d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                    \n",
    "                                if len(model_X) == 1:\n",
    "                                    d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                    \n",
    "                                elif len(model_X) == 2:\n",
    "                                    dates3, values3 = zip(*strat3.scatter_plot_trade_pnl)\n",
    "                                    d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                    d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                \n",
    "                                scatter = pd.concat([bt_df[['Sum']],d5['CDX']],axis=1)\n",
    "                                # scatter = pd.concat([bt_df[['Sum']],d3['CDX']],axis=1)\n",
    "                                x = scatter[scatter['Sum']!=0.0]['CDX'].copy()\n",
    "                                bar_size = sampling_multiplier if dict_models[model_num][0] == 'Intraday' else np.nan\n",
    "                                \n",
    "                                globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_days/trade'].\\\n",
    "                                loc[strategy_zscore_entry,strategy_zscore_exit] = round(x.sum()/(bar_size*len(x)),1)\n",
    "                                \n",
    "                                title = f\"{global_model}; Model {dict_models[model_num][-1]}; {strategy_zscore_entry} entry; {trade_btdf_direction} direction\"\n",
    "                                title += f\" & {strategy_zscore_exit} exit; P/L: {bt_df[['Sum']].cumsum().iloc[-1,0]:.0f}; SR: {sr:.2f}\"\n",
    "                                title += f\" & Diff: {str(diff_period_list)}\"\n",
    "                                \n",
    "                                dates3, values3 = zip(*strat1.scatter_plot_trade_pnl)\n",
    "                                d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                                dates3, values3 = zip(*strat2.scatter_plot_trade_pnl)\n",
    "                                d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                                \n",
    "                                if (model_X) == 1:\n",
    "                                    d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                    \n",
    "                                elif len(model_X) == 2:\n",
    "                                    dates3, values3 = zip(*strat3.scatter_plot_trade_pnl)\n",
    "                                    d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                    d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                \n",
    "                                d5 = d5/bar_size\n",
    "                                scatter = pd.concat([bt_df[['Sum']],d5['CDX']],axis=1)\n",
    "                                scatter = scatter[scatter['Sum']!=0.0]\n",
    "                                plt.figure(figsize=(12,6))\n",
    "                                plt.scatter(scatter['CDX'], scatter['Sum'],label=\"Per Trade P/L\")\n",
    "                                plt.ylabel(\"Trade $P/L\")\n",
    "                                plt.xlabel(\"Trade Duration in Days\")\n",
    "                                plt.title(title)\n",
    "                                plt.legend()\n",
    "                                plt.savefig(f\"Plots/Scatter/{title.replace(\";\",\"_\").replace(\"/\",\"_\").replace(\"&\",\"_\").replace(\":\",\"_\")}.png\")\n",
    "                                # plt.show()\n",
    "                                plt.close()\n",
    "                                 \n",
    "                                bt_df['Sum'].cumsum().plot(label=\"Cum. P/L\", figsize=(12,6))\n",
    "                                plt.title(title)\n",
    "                                plt.legend()\n",
    "                                plt.savefig(f\"Plots/PL/{title.replace(\";\",\"_\").replace(\"/\",\"_\").replace(\"&\",\"_\").replace(\":\",\"_\")}.png\")\n",
    "                                # plt.show()\n",
    "                                plt.close()\n",
    "                                ############################### Plots\n",
    "                        except:\n",
    "                            continue\n",
    "            \n",
    "            display(dfx.iloc[[0,-1],:])\n",
    "            display(f\"ZScore Method is {z_score_method} and diff_period_list is {diff_period_list}\")\n",
    "            for trade_btdf_direction in ['Long/Short']: #'Long','Short',\n",
    "                print(f'global model is {global_model}')\n",
    "                print(f'model_num is {model_num}')\n",
    "                print(f'trade direction is {trade_btdf_direction}')\n",
    "                for info in ['$pnl','$pnl/trade','SR','Hit Ratio','trades','days/trade','max DD']:\n",
    "                    display(globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_{info}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80c15037-0d6d-4c91-b55e-aa3501dd3ab7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# z4 = pd.read_parquet(\"1min ER series v4.parquet\")\n",
    "# z5 = pd.read_parquet(\"1min ER series v5.parquet\")\n",
    "\n",
    "# for col in z4.columns:\n",
    "#     z = pd.concat([z4[[col]], z5[[col]]], axis=1).dropna()\n",
    "#     z.columns = ['v4','v5']\n",
    "#     # z = z/z.iloc[0]\n",
    "#     z.dropna().iloc[-1000*50*100:].plot()\n",
    "#     plt.title(col)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdaef4a6-1891-46be-b594-df4fa4b2d14b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# z4 = pd.read_parquet(\"1min ER series v4.parquet\")\n",
    "# z5 = pd.read_parquet(\"1min ER series v5.parquet\")\n",
    "\n",
    "# for col in z4.columns:\n",
    "#     z = pd.concat([z4[[col]], z5[[col]]], axis=1).dropna()\n",
    "#     z.columns = ['v4','v5']\n",
    "#     z = z/z.iloc[0]\n",
    "#     z.dropna().iloc[-1000*50*100:].plot()\n",
    "#     plt.title(col)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d2aab2-4201-4d17-a905-810add8eb0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
