{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38e670e7-6fdc-4f86-888b-69ffbe02ca11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import asyncio\n",
    "asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())\n",
    "import backtrader as bt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pytz\n",
    "import time\n",
    "import os\n",
    "from xbbg import blp\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import interact, Dropdown, HBox, VBox, Button, Output, Text, widgets\n",
    "import sympy as sp\n",
    "from sklearn.metrics import r2_score\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from IPython import get_ipython\n",
    "import matplotlib.dates as mdates\n",
    "from pydataquery import DataQuery\n",
    "import re\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "import warnings\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import yfinance as yf\n",
    "import csv\n",
    "import uuid\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import warnings\n",
    "from multiprocess import Pool\n",
    "import time\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e88dc18-fb8f-4b5c-942a-22eb26ce8d8e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #ER Code\n",
    "# ####################################################\n",
    "\n",
    "# all_start_date = str((datetime.now()-timedelta(days=13*365+1)).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# labels = {\n",
    "#         \"LQD Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_USDLIG_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"HYG Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_USDHY_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"IEAC Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_EURIG_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"IHYG Funding Sprd\": \"DB(CDS,TRAC-X,EUROPEIBXTRS_EURHY_3M,JPM_IMPLIEDFUNDING_MID)\",\n",
    "#         \"Fed Fund\": \"FF\",\n",
    "#         \"ER CDX IG 5Y\": \"DB(CDS,TRAC-X,NAMERI100UNF05ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX IG 10Y\": \"DB(CDS,TRAC-X,NAMERI100UNF10ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX HY 5Y\": \"DB(CDS,TRAC-X,NAHY100UNF05ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX HY 10Y\": \"DB(CDS,TRAC-X,NAHY100UNF10ONRUN,JPM_RETURN)\",\n",
    "#         \"ER CDX EM 5Y\": \"DB(NEO-UK,credit/cds/index/cdxEM-onrun/5y/JPM_RETURN)\",\n",
    "#         \"ER ITRX MAIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX MAIN 10Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/10y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX XOVER 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX SNRFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_senfin-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "#         \"ER ITRX SUBFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_subfin-onrun/5y/JPM_UNFUNDED_INDEX)\",\n",
    "# }\n",
    "\n",
    "# dq = DataQuery(\n",
    "# client_id='jbAIMF2Tkp0JO3sc',\n",
    "# client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "# )\n",
    "\n",
    "# job = dq.create_job(expressions = list(labels.values()))\n",
    "# dq.start_date = all_start_date\n",
    "# var = job.execute()\n",
    "# df = job.to_pivot_table()\n",
    "# df = df.T\n",
    "# df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "# df.index.name = 'Date'\n",
    "\n",
    "# df.rename(columns={v:k for k, v in labels.items()},inplace=True)\n",
    "# df.columns.name = None\n",
    "# clear_output(wait=False)\n",
    "# df = df.dropna(how='all')\n",
    "# df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# dq = df.copy()\n",
    "\n",
    "# end_date = dq.index[-1]\n",
    "# ####################################### BBG Data Acquisition\n",
    "\n",
    "# securities = ['HYG US Equity','EMB US Equity','LQD US Equity','VCIT US Equity',\n",
    "#               'IEAC LN Equity','IHYG LN EQUITY', 'BKLN US EQUITY', 'IBCN GR EQUITY',\n",
    "#               'IEI US Equity','IEF US Equity']\n",
    "\n",
    "# fields1 = ['YAS_MOD_DUR']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, end_date = end_date, flds = fields1)\n",
    "# df.columns = [item.split(' ')[0] + ' DUR' for item in securities]\n",
    "# df1 = df.copy()\n",
    "\n",
    "# #################################### Fixing Bad Data Point in YAS of IEI\n",
    "# rolling_avg = df1['IEI DUR'].replace(0, np.nan).rolling(window=30, min_periods=1).mean()\n",
    "# df1['IEI DUR'] = df1.apply(\n",
    "#     lambda row: rolling_avg[row.name] if row['IEI DUR'] == 0.0 else row['IEI DUR'], axis=1\n",
    "# )\n",
    "# #################################### Fixing Bad Data Point in YAS of IEI\n",
    "\n",
    "# securities = ['LT03TRUU INDEX','LT09TRUU INDEX','QW3I INDEX', 'LT03MD INDEX','LT09MD INDEX']\n",
    "# fields = ['PX_LAST']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, end_date = end_date, flds = fields)\n",
    "# df.columns = ['TR ' + item.split(' ')[0] for item in securities[:3]] + [item.split(' ')[0] + ' DUR' for item in securities[:2]]\n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# securities = ['HYG US Equity','EMB US Equity','LQD US Equity','VCIT US Equity','HYGH US Equity','LQDH US Equity',\n",
    "#               'IEI US Equity','IEF US Equity', 'RSP US EQUITY', #'SPX INDEX',  'RTY INDEX',\n",
    "#               'IBCN GR EQUITY',\n",
    "#               'IEAC LN Equity','IHYG LN EQUITY', 'BKLN US EQUITY', 'IWM US EQUITY',\n",
    "#               'GSCBHYEQ Index', 'GSCBIGEQ Index', 'SPY US EQUITY', 'EEM US EQUITY','IJH US EQUITY', 'UVXY US EQUITY',\n",
    "#              ]\n",
    "\n",
    "# fields = ['TOT_RETURN_INDEX_GROSS_DVDS']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, end_date = end_date, flds = fields)\n",
    "# df.columns = ['TR ' + item.split(' ')[0] for item in securities] \n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# securities = ['QW3I INDEX']\n",
    "# fields = ['MODIFIED_DURATION']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, end_date = end_date, flds = fields)\n",
    "# df.columns = [item.split(' ')[0] + ' DUR' for item in securities]\n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# # securities = ['SPXFP INDEX', 'RTYFPE INDEX','SX5EFSER Index']  ############## I want to calculate funding rate for spx, rty and sx5e separately\n",
    "# # fields = ['PX_LAST']\n",
    "# # df = blp.bdh(tickers=securities, start_date = all_start_date, end_date = end_date, flds = fields)\n",
    "# # df.columns = ['ER SPX','ER RTY','ER SX5E']\n",
    "# # df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# securities = ['EURR002W Index']\n",
    "# fields = ['PX_LAST']\n",
    "# df = blp.bdh(tickers=securities, start_date = all_start_date, end_date = end_date, flds = fields)\n",
    "# df.columns = ['ECB Rate']\n",
    "# df1 = pd.concat([df,df1],axis=1)\n",
    "\n",
    "# bbg = df1.copy()\n",
    "# dq.index = pd.to_datetime(dq.index)\n",
    "# dq.index = dq.index.date\n",
    "# bbg.index = pd.to_datetime(bbg.index)\n",
    "# bbg.index = bbg.index.date\n",
    "\n",
    "# data = pd.concat([dq,bbg],axis=1)\n",
    "# data = data.sort_index()\n",
    "\n",
    "# df_funding = data[[col for col in data.columns if ('Funding Sprd' in col)]+['Fed Fund']+['ECB Rate']]\n",
    "\n",
    "# if np.isnan(df_funding.loc[df_funding.index[-1],'Fed Fund']):\n",
    "#     df_funding.loc[df_funding.index[-1],'Fed Fund'] = df_funding.loc[df_funding.index[-2],'Fed Fund']\n",
    "\n",
    "# for col in df_funding:\n",
    "#     if col.endswith('Sprd'):\n",
    "#         if col.split(' ')[0] in ['HYG','LQD']:\n",
    "#             df_funding[f'Net Long {col.replace(\" Sprd\",\"\")}'] = (df_funding['Fed Fund'] + df_funding[f'{col}']/100) + 0.25/100\n",
    "#             df_funding[f'Net Short {col.replace(\" Sprd\",\"\")}'] = (df_funding['Fed Fund'] + df_funding[f'{col}']/100) - 0.25/100\n",
    "#         if col.split(' ')[0] in ['IHYG','IEAC']:\n",
    "#             df_funding[f'Net Long {col.replace(\" Sprd\",\"\")}'] = (df_funding['ECB Rate'] + df_funding[f'{col}']/100) + 0.25/100\n",
    "#             df_funding[f'Net Short {col.replace(\" Sprd\",\"\")}'] = (df_funding['ECB Rate'] + df_funding[f'{col}']/100) - 0.25/100\n",
    "\n",
    "# funding_copy_dict = {'VCIT': 'LQD', 'HYGH': 'HYG', 'LQDH': 'LQD'}\n",
    "# for key, val in funding_copy_dict.items():\n",
    "#     df_funding[f'Net Long {key} Funding'] = df_funding[f'Net Long {val} Funding']\n",
    "#     df_funding[f'Net Short {key} Funding'] = df_funding[f'Net Short {val} Funding']\n",
    "\n",
    "# for item in ['EMB','EEM']:\n",
    "#     df_funding[f'Net Long {item} Funding'] = df_funding['Fed Fund'] + 0.5\n",
    "#     df_funding[f'Net Short {item} Funding'] = df_funding['Fed Fund'] - 0.5\n",
    "\n",
    "# for item in ['IEI', 'IEF', 'RSP', 'BKLN', 'GSCBHYEQ', 'GSCBIGEQ', 'SPX', 'RTY', 'SPY', 'IJH','IWM','UVXY']:\n",
    "#     df_funding[f'Net Long {item} Funding'] = df_funding['Fed Fund'] + 0.15\n",
    "#     df_funding[f'Net Short {item} Funding'] = df_funding['Fed Fund'] - 0.15\n",
    "\n",
    "# for item in ['IBCN','SX5E','SX7E']:\n",
    "#     df_funding[f'Net Long {item} Funding'] = df_funding['ECB Rate'] + 0.15\n",
    "#     df_funding[f'Net Short {item} Funding'] = df_funding['ECB Rate'] - 0.15\n",
    "\n",
    "# df_funding = df_funding[[col for col in df_funding.columns if col.startswith(\"Net\")]]\n",
    "# df_funding.index = pd.to_datetime(df_funding.index)\n",
    "# df_funding = df_funding.resample('D').last()\n",
    "\n",
    "# original_er_data = data[[col for col in data.columns if col.startswith(\"ER \")]]\n",
    "# tr_data = data[[col for col in data.columns if col.startswith(\"TR \")]]\n",
    "# ust = tr_data[['TR LT09TRUU']] # for using corr later\n",
    "# tr_data = tr_data.iloc[:,:-3] #dropping LT03/09 and QW3I\n",
    "\n",
    "# tr_data.index = pd.to_datetime(tr_data.index).date\n",
    "# df_funding.index = pd.to_datetime(df_funding.index).date\n",
    "\n",
    "# er_tr_data = pd.concat([tr_data,df_funding],axis=1)\n",
    "# er_tr_data = er_tr_data.sort_index()\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "\n",
    "# etfs = [col for col in er_tr_data.columns if col.startswith(\"TR \")]\n",
    "\n",
    "# for item in etfs:\n",
    "#     er_tr_data[item] = er_tr_data[item].diff()/er_tr_data[item].shift()\n",
    "\n",
    "# er_tr_data['Date'] = pd.to_datetime(er_tr_data.index)\n",
    "# er_tr_data['Days'] = (er_tr_data['Date'] - er_tr_data['Date'].shift()).dt.days\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "# er_tr_data\n",
    "\n",
    "# ############################################################### Funding Sprds\n",
    "# funding = er_tr_data[[col for col in er_tr_data.columns if 'Funding' in col]].copy()\n",
    "# x = er_tr_data[[col for col in er_tr_data.columns if 'Funding' in col]].copy()\n",
    "# x = x.interpolate()\n",
    "# x.to_excel(\"Funding Rates.xlsx\")\n",
    "\n",
    "# # y = x.copy()\n",
    "# # y = round(y,2)\n",
    "# # y.to_excel(\"Funding Rates 2.xlsx\")\n",
    "\n",
    "# ###############################################################\n",
    "# for item in etfs:\n",
    "#     name = item.split(' ')[1]\n",
    "#     er_tr_data[f'ER {name}'] = er_tr_data[item] - \\\n",
    "#                 (1/100)*(er_tr_data['Days']/360)*(0.5*(er_tr_data[f'Net Long {name} Funding'] + er_tr_data[f'Net Short {name} Funding']))\n",
    "\n",
    "\n",
    "# er_tr_data = er_tr_data[[col for col in er_tr_data.columns if col.startswith(\"ER \")]]\n",
    "# er_tr_data = (1+er_tr_data).cumprod()\n",
    "\n",
    "# tr_data.index = pd.to_datetime(tr_data.index).date\n",
    "# df_funding.index = pd.to_datetime(df_funding.index).date\n",
    "\n",
    "# er_tr_data = pd.concat([tr_data,df_funding],axis=1)\n",
    "# er_tr_data = er_tr_data.sort_index()\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "\n",
    "# etfs = [col for col in er_tr_data.columns if col.startswith(\"TR \")]\n",
    "\n",
    "# for item in etfs:\n",
    "#     er_tr_data[item] = er_tr_data[item].diff()/er_tr_data[item].shift()\n",
    "\n",
    "# er_tr_data['Date'] = pd.to_datetime(er_tr_data.index)\n",
    "# er_tr_data['Days'] = (er_tr_data['Date'] - er_tr_data['Date'].shift()).dt.days\n",
    "# # er_tr_data = er_tr_data.dropna()\n",
    "\n",
    "# for item in etfs:\n",
    "#     name = item.split(' ')[1]\n",
    "#     er_tr_data[f'ER {name}'] = er_tr_data[item] - \\\n",
    "#                 (1/100)*(er_tr_data['Days']/360)*(0.5*(er_tr_data[f'Net Long {name} Funding'] + er_tr_data[f'Net Short {name} Funding']))\n",
    "\n",
    "# er_tr_data = er_tr_data[[col for col in er_tr_data.columns if col.startswith(\"ER \")]]\n",
    "# er_tr_data = (1+er_tr_data).cumprod()\n",
    "\n",
    "# er_data = pd.concat([original_er_data,er_tr_data],axis=1)\n",
    "# # er_data = er_data.dropna()\n",
    "# # er_data.columns = er_data.columns.str.replace(\"ER SPX\",\"ER ESA\").str.replace(\"ER RTY\",\"ER RTYA\").str.replace(\"ER SX5E\",\"ER VGA\")\n",
    "# er_data.columns = er_data.columns.str.replace(\"ER GSCBHYEQ\",\"ER HY Eqty\").str.replace(\"ER GSCBIGEQ\",\"ER IG Eqty\")\n",
    "\n",
    "# securities = ['SPXFP INDEX', 'RTYFPE INDEX','SX5EFSER Index','SX7EFSER Index']\n",
    "# fields = ['PX_LAST']\n",
    "# df = blp.bdh(tickers=securities, start_date = er_data.index[0], end_date = er_data.index[-1], flds = fields)\n",
    "# df.columns = ['ER SPX','ER RTY','ER SX5E','ER SX7E']\n",
    "# er_data = pd.concat([er_data,df], axis=1)\n",
    "# er_data = er_data.sort_index()\n",
    "\n",
    "# ##############################################################\n",
    "\n",
    "# vix = blp.bdh(tickers=['SPVIX2ME Index','VIX INDEX','V2X Index'], flds='PX_LAST', start_date=er_data.index[0])\n",
    "# vix.columns = ['ER SPVIX2ME','ER VIX','ER V2X']\n",
    "# er_data = pd.concat([er_data, vix], axis=1).sort_index().dropna().copy()\n",
    "# er_data.to_csv(\"All ER.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8138fe-14a2-49f3-bc17-33df5ce96e49",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# all_start_date = str((datetime.now()-timedelta(days=13*365+1)).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# labels = {\n",
    "#     \"CDX IG 5Y\": \"DB(CDS,TRAC-X,NAMERI100UNF05ONRUN,JPM_DUR)\",\n",
    "#     \"CDX IG 10Y\": \"DB(CDS,TRAC-X,NAMERI100UNF10ONRUN,JPM_DUR)\",\n",
    "#     \"ITRX MAIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/5y/JPM_DUR)\",\n",
    "#     \"ITRX MAIN 10Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/10y/JPM_DUR)\",\n",
    "#     \"ITRX SNRFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_senfin-onrun/5y/JPM_DUR)\",\n",
    "#     \"ITRX SUBFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_subfin-onrun/5y/JPM_DUR)\",\n",
    "#     \"ITRX XOVER 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/5y/JPM_DUR)\",\n",
    "#     \"ITRX XOVER 10Y\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/10y/JPM_DUR)\"\n",
    "# }\n",
    "\n",
    "# dq = DataQuery(\n",
    "# client_id='jbAIMF2Tkp0JO3sc',\n",
    "# client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "# )\n",
    "\n",
    "# job = dq.create_job(expressions = list(labels.values()))\n",
    "# dq.start_date = all_start_date\n",
    "# var = job.execute()\n",
    "# df = job.to_pivot_table()\n",
    "# df = df.T\n",
    "# df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "# df.index.name = 'Date'\n",
    "\n",
    "# df.rename(columns={v:k for k, v in labels.items()},inplace=True)\n",
    "# df.columns.name = None\n",
    "# clear_output(wait=False)\n",
    "# df = df.dropna(how='all')\n",
    "# df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# dur = df.copy()\n",
    "# dur.to_excel(\"DQ Dur.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a90ef8ca-31ba-44e6-9e58-c130be84d3b7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# all_start_date = str((datetime.now()-timedelta(days=13*365+1)).strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# labels = {\n",
    "#     \"CDX IG 5Y\": \"DB(CDS,TRAC-X,NAMERI100UNF05ONRUN,JPM_CDSSPREAD_MID)\",\n",
    "#     \"CDX IG 10Y\": \"DB(CDS,TRAC-X,NAMERI100UNF10ONRUN,JPM_CDSSPREAD_MID)\",\n",
    "#     \"CDX HY 5Y\": \"DB(CDS,TRAC-X,NAHY100UNF05ONRUN,JPM_CLEAN_MID)\",\n",
    "#     \"ITRX MAIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX MAIN 10Y\": \"DB(NEO-UK,credit/cds/index/itraxx-onrun/10y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX SNRFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_senfin-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX SUBFIN 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_subfin-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX XOVER 5Y\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/5y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"ITRX XOVER 10Y\": \"DB(NEO-UK,credit/cds/index/itraxx_crossover-onrun/10y/JPM_CDSSPREAD_MID)\",\n",
    "#     \"CDX EM 5Y\": \"DB(NEO-UK,credit/cds/index/cdxEM-onrun/5y/JPM_CLEAN_MID)\",\n",
    "# }\n",
    "\n",
    "# dq = DataQuery(\n",
    "# client_id='jbAIMF2Tkp0JO3sc',\n",
    "# client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "# )\n",
    "\n",
    "# job = dq.create_job(expressions = list(labels.values()))\n",
    "# dq.start_date = all_start_date\n",
    "# var = job.execute()\n",
    "# df = job.to_pivot_table()\n",
    "# df = df.T\n",
    "# df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "# df.index.name = 'Date'\n",
    "\n",
    "# df.rename(columns={v:k for k, v in labels.items()},inplace=True)\n",
    "# df.columns.name = None\n",
    "# clear_output(wait=False)\n",
    "# df = df.dropna(how='all')\n",
    "# df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# dur = df.copy()\n",
    "# dur.to_excel(\"DQ Ref Levels_PX_Sprd.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d463e11-9e5a-41ad-a11d-dd701918653a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dict_map = {\n",
    "    # product type, start time, end time, carry (%), trades on sprd, slippage (bps or $),\n",
    "    # fixed commission, notional (if selected as Y; moved to model up look up!), BBG ticker\n",
    "    'CDX IG 5Y': ['CDX', '07:45:00', '16:30:00', 1, 'Yes', 0.15, 300, \"CDX IG CDSI GEN 5Y CORP\"],\n",
    "    'CDX IG 10Y': ['CDX', '07:45:00', '16:30:00', 1, 'Yes', 0.3, 300, \"CDX IG CDSI GEN 10Y CORP\"],\n",
    "    'CDX HY 5Y': ['CDX', '07:45:00', '16:30:00', 5, 'No', 0.02, 300, \"CDX HY CDSI GEN 5Y CORP\"],\n",
    "    'SPX': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"SPX INDEX\"],\n",
    "    'SPY': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"SPY US EQUITY\"],\n",
    "    'RSP': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"RSP US INDEX\"],    \n",
    "    'RTY': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"RTY INDEX\"],\n",
    "    'IG Eqty': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"GSCBIGEQ Index\"],\n",
    "    'HY Eqty': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"GSCBHYEQ Index\"],\n",
    "    'ITRX MAIN 5Y': ['CDX', '03:30:00', '11:59:00', 1, 'Yes', 0.15, 300, \"ITRX EUR CDSI GEN 5Y CORP\"],\n",
    "    'ITRX XOVER 5Y': ['CDX', '03:30:00', '11:59:00', 5, 'Yes', 0.15, 300, \"ITRX XOVER CDSI GEN 5Y CORP\"],\n",
    "    \n",
    "    'VIX': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"VIX INDEX\"],\n",
    "    'V2X': ['Eq', '03:30:00', '11:59:00', 0, 'No', 0.01, 0, \"V2X INDEX\"],\n",
    "    'UVXY': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"UVXY US EQUITY\"],\n",
    "    'SPVIX2ME': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"SPVIX2ME INDEX\"],\n",
    "    \n",
    "    'SX5E': ['Eq', '03:30:00', '11:59:00', 0, 'No', 0.01, 0, \"SX5E INDEX\"],\n",
    "    'SX7E': ['Eq', '03:30:00', '11:59:00', 0, 'No', 0.01, 0, \"SX7E INDEX\"],\n",
    "    'ITRX SNRFIN 5Y': ['CDX', '03:30:00', '11:59:00', 1, 'Yes', 0.15, 300, \"SNRFIN CDSI GEN 5Y CORP\"],\n",
    "    'ITRX SUBFIN 5Y': ['CDX', '03:30:00', '11:59:00', 1, 'Yes', 0.15, 300, \"SUBFIN CDSI GEN 5Y CORP\"],\n",
    "    'CDX EM 5Y': ['CDX', '07:45:00', '16:30:00', 1, 'No', 0.02, 300, \"CDX EM CDSI GEN 5Y CORP\"],\n",
    "\n",
    "    'HYG': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"HYG US EQUITY\"],\n",
    "    'HYGH': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.15, 0, \"HYGH US EQUITY\"],\n",
    "    'EMB': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"EMB US EQUITY\"],\n",
    "    'EEM': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"EEM US EQUITY\"],\n",
    "    'VCIT': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"VCIT US EQUITY\"],\n",
    "    'LQD': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"LQD US EQUITY\"],\n",
    "    'LQDH': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.06, 0, \"LQDH US EQUITY\"],\n",
    "    'IEI': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"IEI US EQUITY\"],\n",
    "    'IEF': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"IEF US EQUITY\"],\n",
    "    'IWM': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"IWM US EQUITY\"],\n",
    "    'IJH': ['Eq', '09:30:00', '15:59:00', 0, 'No', 0.01, 0, \"IJH US EQUITY\"],\n",
    "}\n",
    "\n",
    "# er_data = pd.read_csv(\"All ER.csv\", index_col=0, parse_dates=True)\n",
    "# er_data.columns = [item.split(\" \",1)[1] for item in er_data.columns]\n",
    "\n",
    "# # df_backup = pd.read_parquet(\"Clean 1min data.parquet\")\n",
    "# # df_backup = pd.read_parquet(\"Clean 1min data v2.parquet\")\n",
    "# # df_backup = pd.read_parquet(\"Clean 1min data v3.parquet\")\n",
    "# # df_backup = pd.read_parquet(\"Clean 1min data v4.parquet\")\n",
    "# df_backup = pd.read_parquet(\"Clean 1min data v5.parquet\")\n",
    "\n",
    "# ##################################################################\n",
    "\n",
    "# bbg_tickers = [dict_map[item][7] for item in dict_map.keys()]\n",
    "# reverse_dict = dict(zip(bbg_tickers, list(dict_map.keys())))\n",
    "# bbg_data = blp.bdh(tickers = bbg_tickers, flds='px_last', start_date='2017-01-01')\n",
    "# bbg_data.columns = bbg_tickers\n",
    "# bbg_data.index = pd.to_datetime(bbg_data.index)\n",
    "# bbg_data.columns = [reverse_dict[item] for item in bbg_data.columns]\n",
    "# ref = pd.read_excel(\"DQ Ref Levels_PX_Sprd.xlsx\", index_col=0, parse_dates=True)\n",
    "\n",
    "# for col in ref.columns:\n",
    "#     bbg_data[col] = ref[col]\n",
    "\n",
    "# bbg_data1 = bbg_data.resample(\"1min\").last().ffill().copy()\n",
    "# bbg_data1.columns = [item +'_bbg_px' for item in bbg_data1.columns]\n",
    "\n",
    "# bbg_data2 = bbg_data.shift().resample(\"1min\").last().ffill().copy()\n",
    "# bbg_data2.columns = [item +'_bbg_px_2' for item in bbg_data2.columns]\n",
    "\n",
    "# ##################################################################\n",
    "\n",
    "# dur = pd.read_excel(\"DQ Dur.xlsx\",index_col=0, parse_dates=True)\n",
    "# dur = dur.shift().resample(\"1min\").last().ffill().copy()  ############ yesterday's duration we take .. we have shifted it here\n",
    "# dur.columns = [item + '_dq_dur' for item in dur.columns]\n",
    "\n",
    "# df = df_backup.copy()\n",
    "# er = er_data.copy()\n",
    "# er.columns = [item + '_dq_ER' for item in er.columns]\n",
    "# er = er.resample(\"1min\").last().ffill().copy()\n",
    "\n",
    "# er2 = er_data.shift().copy()\n",
    "# er2.columns = [item + '_dq_ER_2' for item in er2.columns]\n",
    "# er2 = er2.resample(\"1min\").last().ffill().copy()\n",
    "\n",
    "# ##################################################################\n",
    "# #### V. V. Imp: the dq close is as of 5PM and with bbg_data only till 4PM we don't really 'see' the BBG ER series match the DQ series\n",
    "\n",
    "# intraday_tr_data = None\n",
    "\n",
    "# for col in df.columns:\n",
    "#     # col = \"IEI\"\n",
    "#     if dict_map[col][4] == 'Yes':\n",
    "#         x = pd.concat([df[[col]], er[[f'{col}_dq_ER']], er2[[f'{col}_dq_ER_2']], bbg_data1[[f'{col}_bbg_px']], bbg_data2[[f'{col}_bbg_px_2']],\n",
    "#             dur[[f'{col}_dq_dur']]], axis=1).sort_index().dropna().copy()\n",
    "#         x['TR Change'] = (x[f'{col}_dq_ER'] / x[f'{col}_dq_ER_2'] - 1)\n",
    "#         x['d-o-d sprd pnl'] = (-1) * (x[f'{col}_dq_dur']) * (x[f'{col}_bbg_px'] - x[f'{col}_bbg_px_2']) * 10**(-4)\n",
    "#         x['intraday sprd pnl'] = (-1) * (x[f'{col}_dq_dur']) * (x[col] - x[f'{col}_bbg_px_2']) * 10**(-4)\n",
    "#         x['Calculated TR Change'] = x['TR Change'] - x['d-o-d sprd pnl'] + x['intraday sprd pnl']\n",
    "#         x['Actual TR Series'] = (1 + x['Calculated TR Change']) * x[f'{col}_dq_ER_2']\n",
    "#         x = x[['Actual TR Series']].copy()\n",
    "#         x.columns = [col]\n",
    "#     else:\n",
    "#         x = pd.concat([df[[col]], er[[f'{col}_dq_ER']], er2[[f'{col}_dq_ER_2']], bbg_data1[[f'{col}_bbg_px']], bbg_data2[[f'{col}_bbg_px_2']],\n",
    "#             ], axis=1).sort_index().dropna().copy()\n",
    "#         x['TR Change'] = (x[f'{col}_dq_ER'] / x[f'{col}_dq_ER_2'] - 1)\n",
    "#         if col in [\"CDX HY 5Y\", \"CDX HY 10Y\", \"CDX EM 5Y\"]:\n",
    "#             x['d-o-d px pnl'] = (x[f'{col}_bbg_px'] - x[f'{col}_bbg_px_2']) * 10**(-2)\n",
    "#             x['intraday px pnl'] = (x[col] - x[f'{col}_bbg_px_2']) * 10**(-2)\n",
    "#         else:  ### it is an etf\n",
    "#             x['d-o-d px pnl'] = (x[f'{col}_bbg_px']/ x[f'{col}_bbg_px_2'] - 1)\n",
    "#             x['intraday px pnl'] = (x[col] / x[f'{col}_bbg_px_2'] - 1)\n",
    "#         x['Calculated TR Change'] = x['TR Change'] - x['d-o-d px pnl'] + x['intraday px pnl']\n",
    "#         x['Actual TR Series'] = (1 + x['Calculated TR Change']) * x[f'{col}_dq_ER_2']\n",
    "#         x = x[['Actual TR Series']].copy()\n",
    "#         x.columns = [col]\n",
    "#     intraday_tr_data = pd.concat([intraday_tr_data, x], axis=1)\n",
    "\n",
    "# # intraday_tr_data.to_parquet(\"1min ER series.parquet\")\n",
    "# # intraday_tr_data.to_parquet(\"1min ER series v2.parquet\")\n",
    "# # intraday_tr_data.to_parquet(\"1min ER series v3.parquet\")\n",
    "# # intraday_tr_data.to_parquet(\"1min ER series v4.parquet\")\n",
    "# intraday_tr_data.to_parquet(\"1min ER series v5.parquet\")\n",
    "\n",
    "# ##################################################################################################################\n",
    "\n",
    "# v4 = pd.read_parquet(\"1min ER series v4.parquet\")\n",
    "# v5 = pd.read_parquet(\"1min ER series v5.parquet\")\n",
    "# v = pd.concat([v4, v5.drop(list(v4.columns),axis=1)], axis=1)\n",
    "# v.to_parquet(\"1min ER series v5.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264ae0db-698f-4824-a051-b7b7ed548d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [ \n",
    "    # model_Y, model_X (specify as a list) ### We trade these\n",
    "    # zscore_Y, zscore_X (specify as a list) ### We use these only for generating the zscore; names are taken from BBG datafile\n",
    "\n",
    "    # ['CDX HY 5Y', ['HYG','IEI'], 'CDX HY 5Y', ['HYG','IEI'], 7*10**6],\n",
    "    # ['CDX EM 5Y', ['EMB','IEF'], 'CDX EM 5Y', ['EMB','IEF'], 9*10**6],\n",
    "    # ['CDX IG 5Y', ['VCIT','IEF'], 'CDX IG 5Y', ['VCIT','IEF'], 25*10**6],\n",
    "    \n",
    "    # ['CDX IG 10Y', ['LQD','IEF'], 'CDX IG 10Y', ['LQD','IEF'], 14*10**6],\n",
    "    # ['CDX IG 5Y', ['SPX'],'CDX IG 5Y', ['SPX'],28*10**6],\n",
    "    # ['CDX IG 5Y', ['RSP'],'CDX IG 5Y', ['RSP'],28*10**6],\n",
    "    # ['CDX IG 5Y', ['IWM'],'CDX IG 5Y', ['IWM'],28*10**6],\n",
    "    # ['CDX IG 5Y', ['IJH'],'CDX IG 5Y', ['IJH'],28*10**6],\n",
    "    # # ['CDX IG 5Y', ['IG Eqty'],'CDX IG 5Y', ['IG Eqty'],28*10**6],\n",
    "    # ['CDX IG 5Y', ['VIX'], 'CDX IG 5Y', ['VIX'], 19*10**6],\n",
    "    # ['CDX IG 5Y', ['SPVIX2ME'], 'CDX IG 5Y', ['SPVIX2ME'], 19*10**6],\n",
    "    \n",
    "    # ['CDX HY 5Y', ['SPX'],'CDX HY 5Y', ['SPX'],6*10**6],\n",
    "    # # ['CDX HY 5Y', ['RTY'],'CDX HY 5Y', ['RTY'],6*10**6],\n",
    "    # # ['CDX HY 5Y', ['RSP'],'CDX HY 5Y', ['RSP'],6*10**6],\n",
    "    # ['CDX HY 5Y', ['IWM'],'CDX HY 5Y', ['IWM'],6*10**6],\n",
    "    # ['CDX HY 5Y', ['IJH'],'CDX HY 5Y', ['IJH'],6*10**6],\n",
    "    # # ['CDX HY 5Y', ['HY Eqty'],'CDX HY 5Y', ['HY Eqty'],6*10**6],\n",
    "    \n",
    "    # # ['ITRX MAIN 5Y', ['SX5E'],'ITRX MAIN 5Y', ['SX5E'], 28*10**6],\n",
    "    # ['ITRX MAIN 5Y', ['SX5E'],'ITRX MAIN 5Y', ['SX5E'], 28*10**6],\n",
    "    # ['ITRX MAIN 5Y', ['SX5E'],'ITRX MAIN 5Y', ['SX5E','V2X'], 28*10**6],\n",
    "    # ['ITRX SNRFIN 5Y', ['SX7E'],'ITRX SNRFIN 5Y', ['SX7E'], 28*10**6],\n",
    "    # # ['ITRX XOVER 5Y', ['SX5E'],'ITRX XOVER 5Y', ['SX5E'], 6*10**6],\n",
    "    # # ['ITRX XOVER 5Y', ['SPX'],'ITRX XOVER 5Y', ['SPX'], 6*10**6],\n",
    "    # # ['CDX IG 5Y', ['ITRX MAIN 5Y'],'CDX IG 5Y', ['ITRX MAIN 5Y'], 50*10**6],\n",
    "    \n",
    "    # # ['CDX HY 5Y', ['ITRX XOVER 5Y'],'CDX HY 5Y', ['ITRX XOVER 5Y'], 8*10**6],\n",
    "    # # ['ITRX MAIN 5Y', ['ITRX XOVER 5Y'],'ITRX MAIN 5Y', ['ITRX XOVER 5Y'], 66*10**6],\n",
    "    # # ['CDX IG 5Y', ['CDX HY 5Y'],'CDX IG 5Y', ['CDX HY 5Y'], 74*10**6],\n",
    "    \n",
    "    # # ['CDX IG 5Y', ['CDX EM 5Y'],'CDX IG 5Y', ['CDX EM 5Y'], 22*10**6],\n",
    "    # # ['CDX EM 5Y', ['CDX HY 5Y'],'CDX EM 5Y', ['CDX HY 5Y'], 8*10**6],\n",
    "    # # ['ITRX MAIN 5Y', ['CDX EM 5Y'],'ITRX MAIN 5Y', ['CDX EM 5Y'], 22*10**6],\n",
    "    # # ['CDX EM 5Y', ['ITRX XOVER 5Y'],'CDX EM 5Y', ['ITRX XOVER 5Y'], 6*10**6],\n",
    "\n",
    "    # # ['CDX IG 5Y', ['SPY'],'CDX IG 5Y', ['SPY'],28*10**6],\n",
    "    # # ['CDX HY 5Y', ['SPY'],'CDX HY 5Y', ['SPY'],6*10**6],\n",
    "    \n",
    "    # # ['EEM', ['EMB'], 'EEM', ['EMB'], 1*10**6],\n",
    "    # # ['CDX EM 5Y', ['EEM'], 'CDX EM 5Y', ['EEM'], 6*10**6],\n",
    "]\n",
    "\n",
    "z_score_method = 'PX'\n",
    "diff_zlist = [[1]]\n",
    "#[[1,2,3], [1], [2], [3], [4], [6], [8], [12]]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "455d0189-5320-4a2a-b5ec-c8aa732c626b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>Dur</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Notional</th>\n",
       "      <th>volume</th>\n",
       "      <th>Long Funding P/L</th>\n",
       "      <th>Short Funding P/L</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-07-01 09:35:00</th>\n",
       "      <td>151.37</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.109331</td>\n",
       "      <td>3.083931e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-04-25 15:55:00</th>\n",
       "      <td>167.45</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.431645</td>\n",
       "      <td>2.401026e+06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      close  Dur    Signal      Notional  volume  \\\n",
       "Date                                                               \n",
       "2021-07-01 09:35:00  151.37 -1.0  0.109331  3.083931e+06     0.0   \n",
       "2025-04-25 15:55:00  167.45 -1.0 -0.431645  2.401026e+06     0.0   \n",
       "\n",
       "                     Long Funding P/L  Short Funding P/L  \n",
       "Date                                                      \n",
       "2021-07-01 09:35:00               0.0               -0.0  \n",
       "2025-04-25 15:55:00               0.0                0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'ZScore Method is PX and diff_period_list is [1]'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global model is ['CDX IG 5Y', ['RSP'], 'CDX IG 5Y', ['RSP'], 28000000]\n",
      "model_num is 1\n",
      "trade direction is Long/Short\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>$pnl</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>-85958.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>275174.0</td>\n",
       "      <td>-102604.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>615592.0</td>\n",
       "      <td>584097.0</td>\n",
       "      <td>75644.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>238538.0</td>\n",
       "      <td>417245.0</td>\n",
       "      <td>217048.0</td>\n",
       "      <td>-252489.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.25</th>\n",
       "      <td>94228.0</td>\n",
       "      <td>323151.0</td>\n",
       "      <td>166041.0</td>\n",
       "      <td>81663.0</td>\n",
       "      <td>-78195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.50</th>\n",
       "      <td>279030.0</td>\n",
       "      <td>464019.0</td>\n",
       "      <td>330707.0</td>\n",
       "      <td>292271.0</td>\n",
       "      <td>163771.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.75</th>\n",
       "      <td>374776.0</td>\n",
       "      <td>387811.0</td>\n",
       "      <td>318535.0</td>\n",
       "      <td>295964.0</td>\n",
       "      <td>220244.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>220984.0</td>\n",
       "      <td>248974.0</td>\n",
       "      <td>164990.0</td>\n",
       "      <td>169604.0</td>\n",
       "      <td>184948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.50</th>\n",
       "      <td>37862.0</td>\n",
       "      <td>166651.0</td>\n",
       "      <td>89046.0</td>\n",
       "      <td>93364.0</td>\n",
       "      <td>32577.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>164359.0</td>\n",
       "      <td>230503.0</td>\n",
       "      <td>176577.0</td>\n",
       "      <td>94742.0</td>\n",
       "      <td>46284.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "$pnl       0.00      0.25      0.50      0.75      1.00\n",
       "Entry                                                  \n",
       "0.25   -85958.0       NaN       NaN       NaN       NaN\n",
       "0.50   275174.0 -102604.0       NaN       NaN       NaN\n",
       "0.75   615592.0  584097.0   75644.0       NaN       NaN\n",
       "1.00   238538.0  417245.0  217048.0 -252489.0       NaN\n",
       "1.25    94228.0  323151.0  166041.0   81663.0  -78195.0\n",
       "1.50   279030.0  464019.0  330707.0  292271.0  163771.0\n",
       "1.75   374776.0  387811.0  318535.0  295964.0  220244.0\n",
       "2.00   220984.0  248974.0  164990.0  169604.0  184948.0\n",
       "2.50    37862.0  166651.0   89046.0   93364.0   32577.0\n",
       "3.00   164359.0  230503.0  176577.0   94742.0   46284.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>$pnl/trade</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>-259.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>1376.0</td>\n",
       "      <td>-310.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>4245.0</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>266.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>2434.0</td>\n",
       "      <td>3477.0</td>\n",
       "      <td>1561.0</td>\n",
       "      <td>-1214.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.25</th>\n",
       "      <td>1346.0</td>\n",
       "      <td>3990.0</td>\n",
       "      <td>1909.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>-463.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.50</th>\n",
       "      <td>5366.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>5421.0</td>\n",
       "      <td>3796.0</td>\n",
       "      <td>1742.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.75</th>\n",
       "      <td>9863.0</td>\n",
       "      <td>9695.0</td>\n",
       "      <td>7584.0</td>\n",
       "      <td>5803.0</td>\n",
       "      <td>3797.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>8185.0</td>\n",
       "      <td>8585.0</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>4711.0</td>\n",
       "      <td>4624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.50</th>\n",
       "      <td>2524.0</td>\n",
       "      <td>9803.0</td>\n",
       "      <td>5238.0</td>\n",
       "      <td>4914.0</td>\n",
       "      <td>1715.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>16436.0</td>\n",
       "      <td>20955.0</td>\n",
       "      <td>16052.0</td>\n",
       "      <td>8613.0</td>\n",
       "      <td>4208.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "$pnl/trade     0.00     0.25     0.50    0.75    1.00\n",
       "Entry                                                \n",
       "0.25         -259.0      NaN      NaN     NaN     NaN\n",
       "0.50         1376.0   -310.0      NaN     NaN     NaN\n",
       "0.75         4245.0   3011.0    266.0     NaN     NaN\n",
       "1.00         2434.0   3477.0   1561.0 -1214.0     NaN\n",
       "1.25         1346.0   3990.0   1909.0   710.0  -463.0\n",
       "1.50         5366.0   8000.0   5421.0  3796.0  1742.0\n",
       "1.75         9863.0   9695.0   7584.0  5803.0  3797.0\n",
       "2.00         8185.0   8585.0   5500.0  4711.0  4624.0\n",
       "2.50         2524.0   9803.0   5238.0  4914.0  1715.0\n",
       "3.00        16436.0  20955.0  16052.0  8613.0  4208.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>SR</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>-0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.38</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.86</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.25</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.50</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.75</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.50</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "SR     0.00  0.25  0.50  0.75  1.00\n",
       "Entry                              \n",
       "0.25  -0.10   NaN   NaN   NaN   NaN\n",
       "0.50   0.38 -0.14   NaN   NaN   NaN\n",
       "0.75   0.86  0.85  0.12   NaN   NaN\n",
       "1.00   0.37  0.67  0.36 -0.35   NaN\n",
       "1.25   0.17  0.55  0.30  0.13 -0.11\n",
       "1.50   0.56  0.90  0.63  0.45  0.26\n",
       "1.75   0.84  0.83  0.68  0.50  0.36\n",
       "2.00   0.58  0.61  0.40  0.31  0.33\n",
       "2.50   0.15  0.50  0.27  0.23  0.08\n",
       "3.00   0.85  0.89  0.70  0.34  0.16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Hit Ratio</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>62.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>66.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>60.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.25</th>\n",
       "      <td>54.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.50</th>\n",
       "      <td>60.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.75</th>\n",
       "      <td>63.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>56.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.50</th>\n",
       "      <td>47.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>70.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Hit Ratio  0.00  0.25  0.50  0.75  1.00\n",
       "Entry                                  \n",
       "0.25       56.0   NaN   NaN   NaN   NaN\n",
       "0.50       62.0  49.0   NaN   NaN   NaN\n",
       "0.75       66.0  63.0  56.0   NaN   NaN\n",
       "1.00       60.0  61.0  60.0  46.0   NaN\n",
       "1.25       54.0  58.0  60.0  52.0  54.0\n",
       "1.50       60.0  62.0  61.0  58.0  59.0\n",
       "1.75       63.0  62.0  62.0  59.0  60.0\n",
       "2.00       56.0  55.0  57.0  56.0  57.0\n",
       "2.50       47.0  47.0  53.0  58.0  53.0\n",
       "3.00       70.0  64.0  64.0  55.0  45.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>trades</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>332.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>200.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>145.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>98.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.25</th>\n",
       "      <td>70.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.50</th>\n",
       "      <td>52.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.75</th>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>27.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.50</th>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "trades   0.00   0.25   0.50   0.75   1.00\n",
       "Entry                                    \n",
       "0.25    332.0    NaN    NaN    NaN    NaN\n",
       "0.50    200.0  331.0    NaN    NaN    NaN\n",
       "0.75    145.0  194.0  284.0    NaN    NaN\n",
       "1.00     98.0  120.0  139.0  208.0    NaN\n",
       "1.25     70.0   81.0   87.0  115.0  169.0\n",
       "1.50     52.0   58.0   61.0   77.0   94.0\n",
       "1.75     38.0   40.0   42.0   51.0   58.0\n",
       "2.00     27.0   29.0   30.0   36.0   40.0\n",
       "2.50     15.0   17.0   17.0   19.0   19.0\n",
       "3.00     10.0   11.0   11.0   11.0   11.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>days/trade</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>3.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>3.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.25</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.50</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.75</th>\n",
       "      <td>4.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.50</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "days/trade  0.00  0.25  0.50  0.75  1.00\n",
       "Entry                                   \n",
       "0.25         2.2   NaN   NaN   NaN   NaN\n",
       "0.50         3.2   1.7   NaN   NaN   NaN\n",
       "0.75         3.6   2.3   1.4   NaN   NaN\n",
       "1.00         4.3   3.0   2.2   1.3   NaN\n",
       "1.25         4.9   3.6   2.9   1.9   1.1\n",
       "1.50         4.8   3.7   3.2   2.2   1.6\n",
       "1.75         4.7   4.1   3.5   2.5   1.9\n",
       "2.00         5.0   4.4   3.8   2.7   2.1\n",
       "2.50         5.5   4.5   3.9   2.9   2.6\n",
       "3.00         5.5   4.5   3.6   2.9   2.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>max DD</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <th>0.75</th>\n",
       "      <th>1.00</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>-681528.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>-403040.0</td>\n",
       "      <td>-548788.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>-223906.0</td>\n",
       "      <td>-178183.0</td>\n",
       "      <td>-315805.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>-272937.0</td>\n",
       "      <td>-191552.0</td>\n",
       "      <td>-192373.0</td>\n",
       "      <td>-491805.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.25</th>\n",
       "      <td>-253797.0</td>\n",
       "      <td>-201805.0</td>\n",
       "      <td>-226693.0</td>\n",
       "      <td>-290153.0</td>\n",
       "      <td>-308542.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.50</th>\n",
       "      <td>-154947.0</td>\n",
       "      <td>-133505.0</td>\n",
       "      <td>-138026.0</td>\n",
       "      <td>-186666.0</td>\n",
       "      <td>-233399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.75</th>\n",
       "      <td>-103412.0</td>\n",
       "      <td>-107384.0</td>\n",
       "      <td>-111950.0</td>\n",
       "      <td>-149131.0</td>\n",
       "      <td>-164898.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.00</th>\n",
       "      <td>-118220.0</td>\n",
       "      <td>-113928.0</td>\n",
       "      <td>-120310.0</td>\n",
       "      <td>-214073.0</td>\n",
       "      <td>-214515.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.50</th>\n",
       "      <td>-75482.0</td>\n",
       "      <td>-76240.0</td>\n",
       "      <td>-88214.0</td>\n",
       "      <td>-128149.0</td>\n",
       "      <td>-146220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.00</th>\n",
       "      <td>-27853.0</td>\n",
       "      <td>-20394.0</td>\n",
       "      <td>-32218.0</td>\n",
       "      <td>-61500.0</td>\n",
       "      <td>-66707.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "max DD      0.00      0.25      0.50      0.75      1.00\n",
       "Entry                                                   \n",
       "0.25   -681528.0       NaN       NaN       NaN       NaN\n",
       "0.50   -403040.0 -548788.0       NaN       NaN       NaN\n",
       "0.75   -223906.0 -178183.0 -315805.0       NaN       NaN\n",
       "1.00   -272937.0 -191552.0 -192373.0 -491805.0       NaN\n",
       "1.25   -253797.0 -201805.0 -226693.0 -290153.0 -308542.0\n",
       "1.50   -154947.0 -133505.0 -138026.0 -186666.0 -233399.0\n",
       "1.75   -103412.0 -107384.0 -111950.0 -149131.0 -164898.0\n",
       "2.00   -118220.0 -113928.0 -120310.0 -214073.0 -214515.0\n",
       "2.50    -75482.0  -76240.0  -88214.0 -128149.0 -146220.0\n",
       "3.00    -27853.0  -20394.0  -32218.0  -61500.0  -66707.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for z_score_method in ['PX','Rtn']:\n",
    "for diff_period_list in diff_zlist:\n",
    "    \n",
    "    dict_models = {\n",
    "        1 : [\"Intraday\",252,252,'A (Intraday; 12M)'],\n",
    "        # 2 : [\"Intraday\",315,315,'B (Intraday; 15M)'],\n",
    "        # 3 : [\"Intraday\",378,378,'C (Intraday; 18M)'],\n",
    "        # 4 : [\"Intraday\",504,504,'D (Intraday; 24M)'],\n",
    "    }\n",
    "    \n",
    "    sampling_freq = '10min'\n",
    "    \n",
    "    for global_model in models_list:\n",
    "        for model_num in list(dict_models.keys()):\n",
    "            for trade_btdf_direction in ['Long','Short','Long/Short']:\n",
    "                for info in ['$pnl','$pnl/trade','SR','Hit Ratio','trades','days/trade','max DD']:\n",
    "                    globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_{info}'] = pd.DataFrame()\n",
    "                    globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_{info}'].index.name = 'Entry'\n",
    "                    globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_{info}'].columns.name = info\n",
    "    \n",
    "    fund_rates = pd.read_excel(\"Funding Rates.xlsx\")\n",
    "    fund_rates.columns = ['Date'] + list(fund_rates.columns)[1:]\n",
    "    fund_rates['Date'] = pd.to_datetime(fund_rates['Date'])\n",
    "    fund_rates = fund_rates.set_index('Date')\n",
    "    fund_rates.columns = fund_rates.columns.str.replace(\"GSCB\",\"\").str.replace(\"EQ \",\" Eqty \").str.replace(\" Funding\",\"\").str.replace(\"Net \",\"\")\n",
    "    etfs = list(set([item.split(\" \",1)[1] for item in fund_rates.columns]))\n",
    "    \n",
    "    def apply_funding(df_funding_update, variable_item):\n",
    "        if f'Long {variable_item}' in fund_rates.columns:\n",
    "            rate = fund_rates[[f'Long {variable_item}',f'Short {variable_item}']].dropna().resample(\"1min\").last().bfill().copy()\n",
    "            df_funding_update = pd.concat([df_funding_update, rate],axis=1)\n",
    "            df_funding_update = df_funding_update.dropna()\n",
    "            df_funding_update.columns = list(df_funding_update.columns)[:-2] + ['Long_Funding','Short_Funding']\n",
    "            df_funding_update['T'] = df_funding_update.index.date\n",
    "            df_funding_update['T-1'] = [np.nan] + list(df_funding_update.index[:-1].date)\n",
    "            df_funding_update['Funding_Date'] = df_funding_update.apply(lambda row: 'New Day' if row['T'] != row['T-1'] else 'Same Day', axis=1)\n",
    "            df_funding_update['Long_Funding'] = df_funding_update.apply(lambda row: row[\"Long_Funding\"] if row[\"Funding_Date\"] == \"New Day\" else 0,axis=1)\n",
    "            df_funding_update['Short_Funding'] = df_funding_update.apply(lambda row: row[\"Short_Funding\"] if row[\"Funding_Date\"] == \"New Day\" else 0,axis=1)\n",
    "            df_funding_update = df_funding_update.drop(['Funding_Date'],axis=1)\n",
    "            # df_funding_update['Funding'] = 0.5*(df_funding_update['Long_Funding'] + df_funding_update['Short_Funding'])\n",
    "            df_funding_update['T-1'] = [item.date() for item in pd.to_datetime(df_funding_update['T-1'])]\n",
    "            df_funding_update['T-1'].iloc[0] = df_funding_update['T'].iloc[0]\n",
    "            df_funding_update['Long Funding P/L'] = [item.days for item in (df_funding_update['T'] - df_funding_update['T-1'])]\n",
    "            df_funding_update['Long Funding P/L'] *= (df_funding_update['Long_Funding'] / 100) * (1/360) * abs(df_funding_update['Notional'])\n",
    "            df_funding_update['Short Funding P/L'] = [item.days for item in (df_funding_update['T'] - df_funding_update['T-1'])]\n",
    "            df_funding_update['Short Funding P/L'] *= (df_funding_update['Short_Funding'] / 100) * (1/360) * abs(df_funding_update['Notional'])\n",
    "            df_funding_update = df_funding_update.drop(['T','T-1','Long_Funding','Short_Funding'],axis=1)\n",
    "        else:\n",
    "            df_funding_update['Long Funding P/L'] = [0.0] * len(df_funding_update)\n",
    "            df_funding_update['Short Funding P/L'] = [0.0] * len(df_funding_update)\n",
    "    \n",
    "        return df_funding_update.copy()\n",
    "    \n",
    "    # bbg_px = pd.read_excel(\"10min data with EUv10.xlsx\", index_col=0, parse_dates=True)\n",
    "    # bbg_px = pd.read_excel(\"10min data with EUv11.xlsx\", index_col=0, parse_dates=True)\n",
    "    # bbg_px = pd.read_excel(\"10min data with EUv12.xlsx\", index_col=0, parse_dates=True)\n",
    "    bbg_px = pd.read_parquet(\"10min data with EUv12.parquet\")\n",
    "    \n",
    "    if z_score_method == \"PX\":\n",
    "        zscore_calc_df = bbg_px.copy()\n",
    "    elif z_score_method == \"Rtn\":\n",
    "        # zscore_calc_df = pd.read_parquet(\"Intraday 1min ER series.parquet\")\n",
    "        # zscore_calc_df = pd.read_parquet(\"1min ER series v3.parquet\")   \n",
    "        # zscore_calc_df = pd.read_parquet(\"1min ER series v4.parquet\")  \n",
    "        zscore_calc_df = pd.read_parquet(\"1min ER series v5.parquet\")  \n",
    "    \n",
    "    for global_model in models_list:\n",
    "        for model_num in list(dict_models.keys()):  \n",
    "    \n",
    "            # global_model = models_list[0]\n",
    "            # model_num = list(dict_models.keys())[0]\n",
    "            \n",
    "            model_Y = global_model[0]\n",
    "            model_X = global_model[1]\n",
    "            zscore_Y = global_model[2]\n",
    "            zscore_X = global_model[3]\n",
    "            backtest_start_date = pd.to_datetime('2017-03-01')\n",
    "            notional_to_use = global_model[4]\n",
    "            \n",
    "            zscore_vars = [model_Y, zscore_Y] + model_X + zscore_X\n",
    "            \n",
    "            zscore_vars = list(set(zscore_vars))\n",
    "            zscore_vars_start_time = max([dict_map[item][1] for item in zscore_vars])\n",
    "            zscore_vars_end_time = min([dict_map[item][2] for item in zscore_vars])\n",
    "            \n",
    "            ################################## Beta Calculation\n",
    "            if len(model_X) == 1:\n",
    "                er_Y = f'ER {model_Y}'\n",
    "                er_X = f'ER {model_X[0]}'\n",
    "                er_data = pd.read_csv(\"All ER.csv\")\n",
    "                er_data.columns = ['Date'] + list(er_data.columns)[1:]\n",
    "                er_data['Date'] = pd.to_datetime(er_data['Date'])\n",
    "                er_data = er_data.set_index('Date')\n",
    "                er_data = er_data.sort_index()\n",
    "                beta = er_data[[er_Y, er_X]].dropna()\n",
    "                beta = beta.resample('W').last()\n",
    "                beta = np.log(beta)\n",
    "                beta = beta.diff().dropna()\n",
    "                beta['Beta1'] = [np.nan] * len(beta)\n",
    "                beta['Beta2'] = [np.nan] * len(beta)\n",
    "                \n",
    "                for i in range(len(beta)-24+1):\n",
    "                    reg_X = beta[er_X].iloc[i:i+24]\n",
    "                    reg_Y = beta[er_Y].iloc[i:i+24]\n",
    "                    model = sm.OLS(reg_Y, sm.add_constant(reg_X)).fit() \n",
    "                    beta.iloc[i+23,2] = model.params.iloc[1]\n",
    "                \n",
    "                    model = sm.OLS(reg_X, sm.add_constant(reg_Y)).fit() \n",
    "                    beta.iloc[i+23,3] = model.params.iloc[1]\n",
    "                \n",
    "                beta['Beta1'] = beta['Beta1'].rolling(104).mean()\n",
    "                beta['Beta2'] = beta['Beta2'].rolling(104).mean()\n",
    "                beta['Beta'] = 0.5*(beta['Beta1'] + 1/ beta['Beta2'])\n",
    "                beta = beta[['Beta']].dropna()\n",
    "                # beta = pd.read_excel(\"igspx_beta_1ymodel.xlsx\", index_col=0, parse_dates=True)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                b1 = pd.read_csv(\"All Basis Trade Betas.csv\")\n",
    "                b1.columns = ['Date'] + list(b1.columns)[1:]\n",
    "                b1 = b1.set_index('Date')\n",
    "                beta = b1[[f'{model_Y}_{model_X[0]}_{model_X[1]}']]\n",
    "                beta.columns = ['Beta']\n",
    "                beta['Coef1'] = beta['Beta'].apply(lambda x: eval(x)[0])\n",
    "                beta['Coef2'] = beta['Beta'].apply(lambda x: eval(x)[1])\n",
    "                beta.index = pd.to_datetime(beta.index)\n",
    "                \n",
    "            beta = beta.resample(\"1min\").first().ffill()\n",
    "            \n",
    "            ################################## BBG DataFile Intraday\n",
    "            # df = pd.read_excel(\"10min data with EUv7.xlsx\")\n",
    "            # df['Date'] = pd.to_datetime(df['Date'])\n",
    "            # df = df.set_index('Date')\n",
    "            # df = df.sort_index()\n",
    "            df = zscore_calc_df.copy()\n",
    "            \n",
    "            zscore_df = df[zscore_vars].between_time(zscore_vars_start_time, zscore_vars_end_time).dropna().copy()\n",
    "            zscore_df = zscore_df.resample(\"10min\",offset=\"5min\").last().dropna().copy()\n",
    "            zscore_df = zscore_df.between_time(zscore_vars_start_time, zscore_vars_end_time).dropna().copy()\n",
    "            bbg_datafile = zscore_df.copy()\n",
    "            \n",
    "            sampling_multiplier = len(set(list(bbg_datafile.index.time)))\n",
    "            \n",
    "            ################################## ZScore Calculation Start : Convert Sprd to PX series\n",
    "            \n",
    "            df = pd.read_excel(\"All DQ Duration.xlsx\")\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df = df.set_index('Date')\n",
    "            df = df.sort_index()\n",
    "            df.columns = df.columns.str.replace(\" Dur\",\"\")\n",
    "            df = df.resample(\"1min\").first().ffill().dropna()\n",
    "            dq_dur = df.copy()\n",
    "            \n",
    "            zscore_df1 = zscore_df.copy()\n",
    "    \n",
    "            if z_score_method == \"PX\":\n",
    "                for col in zscore_df1.columns:\n",
    "                    if col in dq_dur.columns:\n",
    "                        zscore_df1[f'{col} Dur'] = dq_dur[col]\n",
    "                        zscore_df1[f'{col} Dur'] = zscore_df1[f'{col} Dur'].shift(1)\n",
    "                        zscore_df1[f'Diff {col}'] = zscore_df1[col].diff()\n",
    "                        zscore_df1 = zscore_df1.dropna()\n",
    "                        zscore_df1[f'{col} Daily PX Change'] = -1 * zscore_df1[f'Diff {col}'] * zscore_df1[f'{col} Dur'] *10**(-4)\n",
    "                        zscore_df1[f'{col} Sum PX'] = zscore_df1[f'{col} Daily PX Change'].cumsum()\n",
    "                        zscore_df1[col] = zscore_df1[f'{col} Sum PX']\n",
    "                        zscore_df1 = zscore_df1[zscore_df.columns].copy()\n",
    "            \n",
    "            ################################## ZScore Calculation: Differencing and converting to ZScores\n",
    "            \n",
    "            zscore_df = zscore_df1[zscore_df1.index >= backtest_start_date].copy()\n",
    "            \n",
    "            col_list = zscore_df.columns\n",
    "            for period in diff_period_list:\n",
    "                for col in col_list:\n",
    "                    zscore_df[f'{col}_{period}W'] = zscore_df[col].diff(sampling_multiplier*5*period)\n",
    "                    # zscore_df[f'{col}_{period}W'] = zscore_df[col].diff(sampling_multiplier*period)  ##### Daily\n",
    "            \n",
    "            model_lookback = sampling_multiplier*dict_models[model_num][1]\n",
    "            model_lookback_res = sampling_multiplier*dict_models[model_num][2]\n",
    "            zscore_df = zscore_df.dropna().copy()\n",
    "            zscore_df2 = zscore_df.copy()\n",
    "    \n",
    "            for period in diff_period_list:\n",
    "                for i in range(len(zscore_df) - model_lookback + 1):\n",
    "            \n",
    "                    reg_Y = zscore_df[[f'{zscore_Y}_{period}W']].iloc[i:i+model_lookback]\n",
    "                    reg_X = zscore_df[[item + f\"_{period}W\" for item in zscore_X]].iloc[i:i+model_lookback]\n",
    "    \n",
    "                    model = sm.OLS(reg_Y,sm.add_constant(reg_X)).fit()\n",
    "                    x = (model.resid - model.resid.rolling(model_lookback_res).mean())/model.resid.rolling(model_lookback_res).std()\n",
    "                    zscore_df.loc[zscore_df.index[i+model_lookback-1],f'{period}W_ZScore'] = x.iloc[-1]\n",
    "    \n",
    "            zscore_df['Avg. ZScore'] = zscore_df[[col for col in zscore_df.columns if col.endswith(\"_ZScore\")]].mean(axis=1)\n",
    "            zscore_df = zscore_df[['Avg. ZScore']]\n",
    "            bt_df = pd.concat([bbg_datafile[[model_Y] + model_X],zscore_df],axis=1).dropna()   \n",
    "            \n",
    "            #############################################\n",
    "    \n",
    "            if z_score_method == \"Rtn\":\n",
    "                bbg_data = bbg_px.copy()\n",
    "                bbg_data = bbg_data[[model_Y] + model_X].dropna().copy()\n",
    "                bbg_data = bbg_data.resample(\"10min\", offset=\"5min\").last().ffill().copy()\n",
    "                bbg_data = bbg_data[bbg_data.index.isin(bt_df.index)]\n",
    "                for col in bbg_data.columns:\n",
    "                    bt_df[col] = bbg_data[col]\n",
    "                \n",
    "            ############################# If dur > 0 => trades on sprd ; if dur = 0 => cdx trades on px ; if dur = -1 => eq. product trades on px\n",
    "            for col in bt_df.columns:\n",
    "                if col != \"Avg. ZScore\":\n",
    "                    if col in dq_dur.columns:\n",
    "                        bt_df[f'{col} Dur'] = dq_dur[dq_dur.index.isin(bt_df.index)][col]\n",
    "                    elif dict_map[col][0] == 'CDX':\n",
    "                        bt_df[f'{col} Dur'] = [0.0] * len(bt_df)\n",
    "                    elif dict_map[col][0] == 'Eq':\n",
    "                        bt_df[f'{col} Dur'] = [-1.0] * len(bt_df)\n",
    "            bt_df['volume'] = [0.0] * len(bt_df)\n",
    "            \n",
    "            bt_df = bt_df[bt_df.index >= pd.to_datetime(\"2021-07-01\")].dropna()\n",
    "            bt_df = bt_df[bt_df.index <= pd.to_datetime(\"2025-04-26\")].dropna()\n",
    "            \n",
    "            ############################# Backtrader dfs\n",
    "            bt_df = pd.concat([bt_df,beta],axis=1).dropna()\n",
    "            bt_df.columns = bt_df.columns.str.replace(\"Beta\",\"Notional\")\n",
    "            \n",
    "            if len(model_X) == 1:\n",
    "                dfy = bt_df[[model_Y,f'{model_Y} Dur','Avg. ZScore','Notional','volume']].dropna().copy()\n",
    "                dfy.columns = dfy.columns.str.replace(\"Avg. ZScore\",\"Signal\").str.replace(f'{model_Y} Dur','Dur').str.replace(model_Y,\"close\")\n",
    "                dfy['Notional'] = notional_to_use\n",
    "                \n",
    "                dfx = bt_df[[model_X[0],f'{model_X[0]} Dur','Avg. ZScore','Notional','volume']].dropna().copy()\n",
    "                dfx.columns = dfx.columns.str.replace(\"Avg. ZScore\",\"Signal\").str.replace(f'{model_X[0]} Dur','Dur').str.replace(model_X[0],\"close\")\n",
    "                dfx['Notional'] *= notional_to_use\n",
    "                dfx['Signal'] *= -1    \n",
    "            \n",
    "                dfy = apply_funding(dfy.copy(), model_Y)\n",
    "                dfx = apply_funding(dfx.copy(), model_X[0])\n",
    "            \n",
    "            if len(model_X) == 2:\n",
    "                \n",
    "                dfy = bt_df[[model_Y,f'{model_Y} Dur','Avg. ZScore','Notional','volume']].dropna().copy()\n",
    "                dfy.columns = dfy.columns.str.replace(\"Avg. ZScore\",\"Signal\").str.replace(f'{model_Y} Dur','Dur').str.replace(model_Y,\"close\")\n",
    "                dfy['Notional'] = notional_to_use\n",
    "                \n",
    "                dfx = bt_df[[model_X[0],f'{model_X[0]} Dur','Avg. ZScore','Notional','volume']].dropna().copy()\n",
    "                dfx.columns = dfx.columns.str.replace(\"Avg. ZScore\",\"Signal\").str.replace(f'{model_X[0]} Dur','Dur').str.replace(model_X[0],\"close\")\n",
    "                dfx['Notional'] = notional_to_use * bt_df['Coef1']\n",
    "                dfx['Signal'] *= -1   ############################ in basis only hyg px we sell when we buy the residuals so only this will be inverted\n",
    "                \n",
    "                dfx1 = bt_df[[model_X[1],f'{model_X[1]} Dur','Avg. ZScore','Notional','volume']].dropna().copy()\n",
    "                dfx1.columns = dfx1.columns.str.replace(\"Avg. ZScore\",\"Signal\").str.replace(f'{model_X[1]} Dur','Dur').str.replace(model_X[1],\"close\")\n",
    "                dfx1['Notional'] = notional_to_use * bt_df['Coef2']\n",
    "            \n",
    "                dfy = apply_funding(dfy.copy(), model_Y)\n",
    "                dfx = apply_funding(dfx.copy(), model_X[0])\n",
    "                dfx1 = apply_funding(dfx1.copy(), model_X[1])\n",
    "            \n",
    "            \n",
    "            class MyData(bt.feeds.PandasData):\n",
    "                lines = ('signal', 'notional', 'dur', 'long_funding', 'short_funding')\n",
    "                params = (('signal', 'Signal'), ('notional', 'Notional'), \n",
    "                          ('dur', 'Dur'), ('long_funding', 'Long Funding P/L'), ('short_funding', 'Short Funding P/L'))\n",
    "            \n",
    "            class FixedComm(bt.CommInfoBase):\n",
    "                params = (('commission', 0), ('stocklike', True), ('commtype', bt.CommInfoBase.COMM_FIXED),)\n",
    "                def _getcommission(self, size, price, pseudoexec):\n",
    "                    return self.p.commission\n",
    "            \n",
    "            class TStrategy(bt.Strategy):\n",
    "                params = dict(cheat_on_close=True, entry_zscore = 0, exit_zscore = 0, carry = 0, product = 'Untitled')\n",
    "                \n",
    "                def __init__(self):\n",
    "                    self.portfolio_values = []\n",
    "                    self.entry_date = None\n",
    "                    self.daily_pnl = []\n",
    "                    self.roll_trades = []\n",
    "                    self.carry = []\n",
    "                    self.roll_carry = []\n",
    "                    \n",
    "                    self.funding = []\n",
    "                    self.funding_carry = []\n",
    "                    self.funding_direction = None\n",
    "                    self.entry_bar_funding = None\n",
    "                    \n",
    "                    self.trade_direction = []\n",
    "                    \n",
    "                    self.scatter_plot_trade_pnl = []\n",
    "                    self.scatter_plot_trade_init_len = None\n",
    "                    \n",
    "                    self.carry_direction = 0\n",
    "                    self.logs = []\n",
    "            \n",
    "                def log(self, txt):\n",
    "                    dt = self.datas[0].datetime.datetime(0)\n",
    "                    print(f'{dt} - {txt}')\n",
    "                    self.logs.append([dt.isoformat(), txt])\n",
    "            \n",
    "                def notify_trade(self, trade):            \n",
    "                    if trade.isclosed:            \n",
    "                        current_date = self.datas[0].datetime.datetime(-1)\n",
    "                        \n",
    "                        self.trade_direction.append((current_date, self.funding_direction if self.p.product == model_Y else None)) \n",
    "                        #### Y determines the long/short direction\n",
    "                        \n",
    "                        \n",
    "                        ######################################## Calculating carry for all trades\n",
    "                        self.daily_pnl.append((current_date, trade.pnlcomm))\n",
    "            \n",
    "                        if self.carry_direction > 0 : \n",
    "                            self.carry.append((current_date, (current_date.date()-self.entry_date.\\\n",
    "                                                              date()).days*(1/360)*self.p.carry*(1/100)*self.datas[0].notional[0]))\n",
    "                        elif self.carry_direction < 0 :\n",
    "                            self.carry.append((current_date, -1*(current_date.date()-self.entry_date.\\\n",
    "                                                             date()).days*(1/360)*self.p.carry*(1/100)*self.datas[0].notional[0]))\n",
    "                        \n",
    "                        ######################################## Calculating funding for all trades\n",
    "                        bars_active = len(self) - self.entry_bar_funding - 1\n",
    "                        \n",
    "                        if self.funding_direction == \"Long\":\n",
    "                            values = [self.datas[0].long_funding[-i] for i in range(bars_active)]\n",
    "                            rolling_sum = -1*sum(values)  ############ We pay the long funding\n",
    "                        \n",
    "                        elif self.funding_direction == \"Short\":\n",
    "                            values = [self.datas[0].short_funding[-i] for i in range(bars_active)]\n",
    "                            rolling_sum = sum(values)  ############ We earn the short funding\n",
    "                            \n",
    "                        self.funding.append((current_date, rolling_sum))\n",
    "            \n",
    "                        \n",
    "                        p1 = [datetime(current_date.year, 3, 20), datetime(current_date.year, 3, 30)]\n",
    "                        p2 = [datetime(current_date.year, 9, 20), datetime(current_date.year, 9, 30)]\n",
    "                        p3 = [datetime(current_date.year+1, 3, 20), datetime(current_date.year+1, 3, 30)]\n",
    "                        p4 = [datetime(current_date.year-1, 9, 20), datetime(current_date.year-1, 9, 30)]\n",
    "                        periods = [p1, p2, p3, p4]\n",
    "                        \n",
    "                        ######################################## Calculating carry for roll trades separately\n",
    "                        \n",
    "                        for i in range(len(periods)):\n",
    "                            p = periods[i]\n",
    "                            if ((self.entry_date <= p[1]) and (p[0] <= current_date)):\n",
    "                                self.roll_trades.append((current_date, trade.pnlcomm))\n",
    "                                if self.carry_direction > 0:\n",
    "                                    self.roll_carry.append((current_date, (current_date.date()-self.entry_date.\\\n",
    "                                                                   date()).days*(1/360)*self.p.carry*(1/100)*self.datas[0].notional[0]))\n",
    "                                elif self.carry_direction < 0:\n",
    "                                    self.roll_carry.append((current_date, -1*(current_date.date()-self.entry_date.\\\n",
    "                                                                  date()).days*(1/360)*self.p.carry*(1/100)*self.datas[0].notional[0]))\n",
    "            \n",
    "                                self.funding_carry.append((current_date, rolling_sum))\n",
    "                                \n",
    "                                break\n",
    "                        \n",
    "                        ################################################# All trades\n",
    "                        \n",
    "                        # self.log(f'Gross P/L: {trade.pnl:.2f}, Net P/L: {trade.pnlcomm:.2f}, Funding P/L: {rolling_sum:.2f}')        \n",
    "                        self.carry_direction = 0\n",
    "            \n",
    "                # def notify_order(self, order):\n",
    "                #     if order.status in [order.Completed]:\n",
    "                #         if order.isbuy():\n",
    "                #             self.log(f'BUY EXECUTED, PX: {order.executed.price:.4f}, Qty: {order.executed.size:.2f}, Comm: {order.executed.comm}')\n",
    "                #         else:\n",
    "                #             self.log(f'SELL EXECUTED, PX: {order.executed.price:.4f}, Qty: {order.executed.size:.2f}, Comm: {order.executed.comm}')\n",
    "            \n",
    "                def next(self):\n",
    "                    self.broker.set_coc(self.p.cheat_on_close)\n",
    "                    # val = None\n",
    "                    self.portfolio_values.append((self.datas[0].datetime.datetime(0), self.broker.getvalue()))\n",
    "                    \n",
    "                    z = self.datas[0].signal[0]\n",
    "                    px = self.datas[0].close[0]        \n",
    "                    pos = self.getposition(self.datas[0]).size\n",
    "            \n",
    "                    # self.log(f'PX: {px}, ZScore: {z:.3f}, Notional: {self.datas[0].notional[0]:.0f}, Dur: {self.datas[0].dur[0]:.4f} '\n",
    "                    #          f'Pos: {pos:.2f}, Long Funding $: {self.datas[0].long_funding[0]:.2f}, Short Funding $: {self.datas[0].short_funding[0]:.2f} '\n",
    "                    #          f'Eqty (000): {(self.broker.getvalue()-1e12)*10**(-3):.2f}')\n",
    "                    \n",
    "                    if pos == 0:                \n",
    "                        if z < -self.p.entry_zscore:\n",
    "                            self.scatter_plot_trade_init_len = len(self)\n",
    "                            self.entry_date = self.datas[0].datetime.datetime(0)\n",
    "            \n",
    "                            if self.datas[0].dur[0] == -1:\n",
    "                                self.buy(data = self.data, size = self.datas[0].notional[0]/px)\n",
    "                            elif self.datas[0].dur[0] == 0.0:\n",
    "                                self.buy(data=self.datas[0], size = (self.datas[0].notional[0] / 100))\n",
    "                            elif self.datas[0].dur[0] > 0.0:\n",
    "                                self.sell(data=self.data, size = (self.datas[0].notional[0])*10**(-4)*self.datas[0].dur[0])\n",
    "            \n",
    "                            self.carry_direction = 1\n",
    "                            self.entry_bar_funding = len(self)\n",
    "                            self.funding_direction = \"Long\"\n",
    "            \n",
    "                        elif z > self.p.entry_zscore:\n",
    "                            self.scatter_plot_trade_init_len = len(self)\n",
    "                            self.entry_date = self.datas[0].datetime.datetime(0)\n",
    "            \n",
    "                            if self.datas[0].dur[0] == -1:\n",
    "                                self.sell(data = self.data, size = self.datas[0].notional[0]/px)\n",
    "                            elif self.datas[0].dur[0] == 0.0:\n",
    "                                self.sell(data=self.datas[0], size = (self.datas[0].notional[0] / 100))\n",
    "                            elif self.datas[0].dur[0] > 0.0:\n",
    "                                self.buy(data=self.data, size = (self.datas[0].notional[0])*10**(-4)*self.datas[0].dur[0])\n",
    "            \n",
    "                            self.carry_direction = -1\n",
    "                            self.entry_bar_funding = len(self)\n",
    "                            self.funding_direction = \"Short\"\n",
    "                            \n",
    "                    else:\n",
    "                            if self.datas[0].dur[0] <= 0.0: ######## Equity & CDX HY\n",
    "                                if ((pos > 0 and z > -self.p.exit_zscore) or (pos < 0 and z < self.p.exit_zscore)):\n",
    "                                    self.close(data=self.datas[0])\n",
    "                                    self.scatter_plot_trade_pnl.append((self.datas[0].datetime.\\\n",
    "                                                        datetime(0), len(self) - self.scatter_plot_trade_init_len))\n",
    "                            \n",
    "                            elif self.datas[0].dur[0] > 0.0: ######## CDX IG\n",
    "                                if ((pos < 0 and z > -self.p.exit_zscore) or (pos > 0 and z < self.p.exit_zscore)):\n",
    "                                    self.close(data=self.datas[0])\n",
    "                                    self.scatter_plot_trade_pnl.append((self.datas[0].datetime.\\\n",
    "                                                        datetime(0), len(self) - self.scatter_plot_trade_init_len))\n",
    "            \n",
    "            \n",
    "                # def stop(self):\n",
    "                #     # with open(f'{self.p.product}.csv', 'w', newline='') as f:\n",
    "                #     with open(f'backtrader_log_{str(datetime.now().time()).replace(\":\",\"_\")}.csv', 'w', newline='') as f:\n",
    "                #         writer = csv.writer(f)\n",
    "                #         writer.writerow(['Date','Message'])\n",
    "                #         writer.writerows(self.logs)\n",
    "            \n",
    "            for strategy_zscore_exit in [0.0, 0.25, 0.5, 0.75, 1.0]:\n",
    "                for strategy_zscore_entry in [0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.5, 3.0]:\n",
    "                    if strategy_zscore_entry > strategy_zscore_exit:\n",
    "            \n",
    "                        cerebro1 = bt.Cerebro()\n",
    "                        cerebro1.addstrategy(TStrategy, cheat_on_close=True, entry_zscore = strategy_zscore_entry, exit_zscore = strategy_zscore_exit,\\\n",
    "                                             carry = dict_map[model_Y][3], product = model_Y)\n",
    "                        \n",
    "                        cerebro1.broker.setcash(1e12)\n",
    "                        feed1 = MyData(dataname=dfy.copy(), timeframe=bt.TimeFrame.Minutes)\n",
    "                        cerebro1.adddata(feed1)\n",
    "                        cerebro1.broker.set_slippage_fixed(fixed=dict_map[model_Y][5], slip_open=True, slip_limit=True, slip_match=True, slip_out=True)\n",
    "                        cerebro1.broker.setcommission(margin=0.00001, mult=1)\n",
    "                        cerebro1.broker.addcommissioninfo(FixedComm(commission=dict_map[model_Y][6]))\n",
    "                        cerebro1.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trade_analyzer')\n",
    "                        results1 = cerebro1.run()\n",
    "                        \n",
    "                        cerebro2 = bt.Cerebro()\n",
    "                        cerebro2.addstrategy(TStrategy, cheat_on_close=True, entry_zscore = strategy_zscore_entry, exit_zscore = strategy_zscore_exit,\\\n",
    "                                             carry = dict_map[model_X[0]][3], product = model_X[0])\n",
    "                        cerebro2.broker.setcash(1e12)\n",
    "                        feed2 = MyData(dataname=dfx.copy(), timeframe=bt.TimeFrame.Minutes)\n",
    "                        cerebro2.adddata(feed2)\n",
    "                        cerebro2.broker.set_slippage_fixed(fixed=dict_map[model_X[0]][5], slip_open=True, slip_limit=True, slip_match=True, slip_out=True)\n",
    "                        cerebro2.broker.setcommission(margin=0.00001, mult=1)\n",
    "                        cerebro1.broker.addcommissioninfo(FixedComm(commission=dict_map[model_X[0]][6]))\n",
    "                        cerebro2.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trade_analyzer')\n",
    "                        results2 = cerebro2.run()\n",
    "            \n",
    "                        if len(model_X) == 2:\n",
    "                            cerebro3 = bt.Cerebro()\n",
    "                            cerebro3.addstrategy(TStrategy, cheat_on_close=True, entry_zscore = strategy_zscore_entry, \\\n",
    "                                                 exit_zscore = strategy_zscore_exit,\\\n",
    "                                                 carry = dict_map[model_X[1]][3], product = model_X[1])\n",
    "                            cerebro3.broker.setcash(1e12)\n",
    "                            feed3 = MyData(dataname=dfx1.copy(), timeframe=bt.TimeFrame.Minutes)\n",
    "                            cerebro3.adddata(feed3)\n",
    "                            cerebro3.broker.set_slippage_fixed(fixed=dict_map[model_X[1]][5], slip_open=True, slip_limit=True, \\\n",
    "                                                               slip_match=True, slip_out=True)\n",
    "                            cerebro3.broker.setcommission(margin=0.00001, mult=1)\n",
    "                            cerebro1.broker.addcommissioninfo(FixedComm(commission=dict_map[model_X[1]][6]))\n",
    "                            cerebro3.addanalyzer(bt.analyzers.TradeAnalyzer, _name='trade_analyzer')\n",
    "                            results3 = cerebro3.run()\n",
    "            \n",
    "                        \n",
    "                        strat1 = results1[0]\n",
    "                        dates1, values1 = zip(*strat1.portfolio_values)\n",
    "                        \n",
    "                        strat2 = results2[0]\n",
    "                        dates2, values2 = zip(*strat2.portfolio_values)\n",
    "            \n",
    "                        if len(model_X) == 2:\n",
    "                            strat3 = results3[0]\n",
    "                            dates3, values3 = zip(*strat3.portfolio_values)\n",
    "                        \n",
    "                        # clear_output(wait=False)\n",
    "                        \n",
    "                        \n",
    "                        #############################################################################################################################\n",
    "                        \n",
    "                        ############################################### Basic PX based P/L\n",
    "                        try:\n",
    "                            dates3, values3 = zip(*strat1.daily_pnl)\n",
    "                            d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                            dates3, values3 = zip(*strat2.daily_pnl)\n",
    "                            d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                \n",
    "                            if len(model_X) == 1:\n",
    "                                d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                                d5['Daily P/L'] = d5['CDX'] + d5['SPX']\n",
    "                            \n",
    "                            elif len(model_X) == 2:\n",
    "                                dates3, values3 = zip(*strat3.daily_pnl)\n",
    "                                d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                d5['Daily P/L'] = d5['CDX'] + d5['SPX'] + d5['SPX2']\n",
    "                \n",
    "                            d5 = round(d5[['Daily P/L']].astype(float),2)\n",
    "                            daily_pnl = d5.copy()\n",
    "                \n",
    "                            ############################################### Removing Roll basic PX P/L\n",
    "                            try:\n",
    "                                dates3, values3 = zip(*strat1.roll_trades)\n",
    "                                d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                                dates3, values3 = zip(*strat2.roll_trades)\n",
    "                                d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                \n",
    "                                if len(model_X) == 1:\n",
    "                                    d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                                    d5['Roll P/L'] = d5['CDX'] + d5['SPX']\n",
    "                                \n",
    "                                elif len(model_X) == 2:\n",
    "                                    dates3, values3 = zip(*strat3.roll_trades)\n",
    "                                    d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                    d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                    d5['Roll P/L'] = d5['CDX'] + d5['SPX'] + d5['SPX2']\n",
    "                \n",
    "                                d5 = -1*round(d5[['Roll P/L']].astype(float),2)\n",
    "                                roll_trades = d5.copy()\n",
    "                            except Exception as e:\n",
    "                                roll_trades = pd.DataFrame()\n",
    "                \n",
    "                            ############################################### Adding all trades carry\n",
    "                            try:\n",
    "                                dates3, values3 = zip(*strat1.carry)\n",
    "                                d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                                dates3, values3 = zip(*strat2.carry)\n",
    "                                d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                \n",
    "                                if len(model_X) == 1:\n",
    "                                    d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                                    d5['CDX Carry'] = d5['CDX'] + d5['SPX']\n",
    "                                    \n",
    "                                elif len(model_X) == 2:\n",
    "                                    dates3, values3 = zip(*strat3.carry)\n",
    "                                    d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                    d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                    d5['CDX Carry'] = d5['CDX'] + d5['SPX'] + d5['SPX2']\n",
    "                \n",
    "                                d5 = round(d5[['CDX Carry']].astype(float),2)\n",
    "                                carry = d5.copy()\n",
    "                            except Exception as e:\n",
    "                                carry = pd.DataFrame()\n",
    "                            \n",
    "                            ############################################### Remove carry of roll trades\n",
    "                            \n",
    "                            try:\n",
    "                                dates3, values3 = zip(*strat1.roll_carry)\n",
    "                                d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                                dates3, values3 = zip(*strat2.roll_carry)\n",
    "                                d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                \n",
    "                                if len(model_X) == 1:\n",
    "                                    d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                                    d5['CDX Roll Carry'] = d5['CDX'] + d5['SPX']\n",
    "                \n",
    "                                elif len(model_X) == 2:\n",
    "                                    dates3, values3 = zip(*strat3.roll_carry)\n",
    "                                    d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                    d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                    d5['CDX Roll Carry'] = d5['CDX'] + d5['SPX'] + d5['SPX2']\n",
    "                \n",
    "                                d5 = -1*round(d5[['CDX Roll Carry']].astype(float),2)\n",
    "                                roll_carry = d5.copy()\n",
    "                            except Exception as e:\n",
    "                                roll_carry = pd.DataFrame()\n",
    "                \n",
    "                            ############################################### Add funding of all trades\n",
    "                            \n",
    "                            try:\n",
    "                                dates3, values3 = zip(*strat1.funding)\n",
    "                                d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                                dates3, values3 = zip(*strat2.funding)\n",
    "                                d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                \n",
    "                                if len(model_X) == 1:\n",
    "                                    d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                                    d5['Funding'] = d5['CDX'] + d5['SPX']\n",
    "                \n",
    "                                elif len(model_X) == 2:\n",
    "                                    dates3, values3 = zip(*strat3.funding)\n",
    "                                    d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                    d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                    d5['Funding'] = d5['CDX'] + d5['SPX'] + d5['SPX2']\n",
    "                \n",
    "                                d5 = round(d5[['Funding']].astype(float),2)\n",
    "                                funding = d5.copy()\n",
    "                            except Exception as e:\n",
    "                                funding = pd.DataFrame()\n",
    "                                \n",
    "                            ############################################### Remove funding of carry trades\n",
    "                            \n",
    "                            try:\n",
    "                                dates3, values3 = zip(*strat1.funding_carry)\n",
    "                                d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                                dates3, values3 = zip(*strat2.funding_carry)\n",
    "                                d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                \n",
    "                                if len(model_X) == 1:\n",
    "                                    d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                                    d5['funding_carry'] = d5['CDX'] + d5['SPX']\n",
    "                \n",
    "                                elif len(model_X) == 2:\n",
    "                                    dates3, values3 = zip(*strat3.funding_carry)\n",
    "                                    d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                    d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                    d5['funding_carry'] = d5['CDX'] + d5['SPX'] + d5['SPX2']\n",
    "                \n",
    "                                d5 = -1*round(d5[['funding_carry']].astype(float),2)\n",
    "                                funding_carry = d5.copy()\n",
    "                            except Exception as e:\n",
    "                                funding_carry = pd.DataFrame()\n",
    "                \n",
    "                            #############################################################################################################################\n",
    "                \n",
    "                            dates3, values3 = zip(*strat1.trade_direction)\n",
    "                            long_short_ind = pd.DataFrame({ 'Ind':list(values3)}, index = list(dates3))\n",
    "                            \n",
    "                            bt_df = pd.concat([dfy[['volume']], daily_pnl, roll_trades, carry, roll_carry, funding, funding_carry],axis=1)\n",
    "                            bt_df = bt_df.iloc[:,1:]\n",
    "                            bt_df = bt_df.fillna(0.0)\n",
    "    \n",
    "    \n",
    "                            ####### Keep commented to adjust for funding; if no funding then remove the hash    \n",
    "                            ####### these are when want to tally with old model outputs                        \n",
    "                            # bt_df['Funding'] = [0.0] * len(bt_df)\n",
    "                            # bt_df['funding_carry'] = [0.0] * len(bt_df)\n",
    "                            \n",
    "                            bt_df_backup = bt_df.copy()\n",
    "                            \n",
    "                            for trade_btdf_direction in ['Long/Short']: #'Long','Short',\n",
    "                                bt_df = bt_df_backup.copy()\n",
    "                                \n",
    "                                trade_check = None if trade_btdf_direction == 'Long/Short' else trade_btdf_direction\n",
    "                                \n",
    "                                bt_df['Sum'] = bt_df.sum(axis=1)\n",
    "                                x = pd.concat([bt_df, long_short_ind],axis=1).copy()\n",
    "                                x = x[x['Ind']!=trade_check].drop(\"Ind\",axis=1).copy()   ###### Use not equal operator\n",
    "                                x = pd.concat([dfy[['volume']],x],axis=1).copy()\n",
    "                                x = x.iloc[:,1:].fillna(0.0)\n",
    "                                bt_df = x.copy()\n",
    "                                trade_num = len(bt_df[bt_df['Sum']!=0])\n",
    "                                bt_df = bt_df.drop(\"Sum\",axis=1)\n",
    "                \n",
    "                \n",
    "                                ###########################################################################################################################\n",
    "                \n",
    "                                sr = bt_df.copy()\n",
    "                                sr['Sum'] = sr.sum(axis=1)\n",
    "                                sr = sr[['Sum']]\n",
    "                                sr = sr.cumsum().resample(\"D\").last().dropna().copy()\n",
    "                                sr += 10**7\n",
    "                                sr = sr.pct_change()\n",
    "                                sr = round((252**0.5*sr.mean()/sr.std()).iloc[0],3)\n",
    "                                \n",
    "                                globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_$pnl'].\\\n",
    "                                loc[strategy_zscore_entry,strategy_zscore_exit] = round(bt_df.sum().sum(),0)\n",
    "                                globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_$pnl/trade'].\\\n",
    "                                loc[strategy_zscore_entry,strategy_zscore_exit] = round(bt_df.sum().sum()/trade_num,0)\n",
    "                                globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_SR'].\\\n",
    "                                loc[strategy_zscore_entry,strategy_zscore_exit] = round(sr,2)\n",
    "                                globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_trades'].\\\n",
    "                                loc[strategy_zscore_entry,strategy_zscore_exit] = trade_num\n",
    "                \n",
    "                                bt_df['Sum'] = bt_df.sum(axis=1)\n",
    "                                pos = len(bt_df[bt_df['Sum']>0])\n",
    "                                neg = len(bt_df[bt_df['Sum']<0])\n",
    "                                try:\n",
    "                                    hit = round((pos/(pos+neg))*100,0)\n",
    "                                except:\n",
    "                                    hit = 0\n",
    "                                globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_Hit Ratio'].\\\n",
    "                                loc[strategy_zscore_entry,strategy_zscore_exit] = round(hit,0)\n",
    "                    \n",
    "                                max_dd = bt_df[['Sum']].cumsum().copy()\n",
    "                                max_dd['Roll Max'] = max_dd[['Sum']].rolling(window=10000000, min_periods=1).max()\n",
    "                                max_dd['Diff'] = abs(max_dd['Roll Max'] - max_dd['Sum'])\n",
    "                                globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_max DD'].\\\n",
    "                                loc[strategy_zscore_entry,strategy_zscore_exit] = round(-1*max_dd['Diff'].max(),0)\n",
    "                                \n",
    "                                ############################### Plots\n",
    "                                \n",
    "                                dates3, values3 = zip(*strat1.scatter_plot_trade_pnl)\n",
    "                                d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                                dates3, values3 = zip(*strat2.scatter_plot_trade_pnl)\n",
    "                                d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                    \n",
    "                                if len(model_X) == 1:\n",
    "                                    d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                    \n",
    "                                elif len(model_X) == 2:\n",
    "                                    dates3, values3 = zip(*strat3.scatter_plot_trade_pnl)\n",
    "                                    d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                    d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                \n",
    "                                scatter = pd.concat([bt_df[['Sum']],d5['CDX']],axis=1)\n",
    "                                # scatter = pd.concat([bt_df[['Sum']],d3['CDX']],axis=1)\n",
    "                                x = scatter[scatter['Sum']!=0.0]['CDX'].copy()\n",
    "                                bar_size = sampling_multiplier if dict_models[model_num][0] == 'Intraday' else np.nan\n",
    "                                \n",
    "                                globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_days/trade'].\\\n",
    "                                loc[strategy_zscore_entry,strategy_zscore_exit] = round(x.sum()/(bar_size*len(x)),1)\n",
    "                                \n",
    "                                title = f\"{global_model}; Model {dict_models[model_num][-1]}; {strategy_zscore_entry} entry; {trade_btdf_direction} direction\"\n",
    "                                title += f\" & {strategy_zscore_exit} exit; P/L: {bt_df[['Sum']].cumsum().iloc[-1,0]:.0f}; SR: {sr:.2f}\"\n",
    "                                title += f\" & Diff: {str(diff_period_list)}\"\n",
    "                                \n",
    "                                dates3, values3 = zip(*strat1.scatter_plot_trade_pnl)\n",
    "                                d3 = pd.DataFrame({ 'CDX':list(values3)}, index = list(dates3))\n",
    "                                dates3, values3 = zip(*strat2.scatter_plot_trade_pnl)\n",
    "                                d4 = pd.DataFrame({ 'SPX':list(values3)}, index = list(dates3))\n",
    "                                \n",
    "                                if (model_X) == 1:\n",
    "                                    d5 = pd.concat([d3,d4],axis=1).dropna().copy()\n",
    "                    \n",
    "                                elif len(model_X) == 2:\n",
    "                                    dates3, values3 = zip(*strat3.scatter_plot_trade_pnl)\n",
    "                                    d41 = pd.DataFrame({ 'SPX2':list(values3)}, index = list(dates3))\n",
    "                                    d5 = pd.concat([d3,d4,d41],axis=1).dropna().copy()\n",
    "                                \n",
    "                                d5 = d5/bar_size\n",
    "                                scatter = pd.concat([bt_df[['Sum']],d5['CDX']],axis=1)\n",
    "                                scatter = scatter[scatter['Sum']!=0.0]\n",
    "                                plt.figure(figsize=(12,6))\n",
    "                                plt.scatter(scatter['CDX'], scatter['Sum'],label=\"Per Trade P/L\")\n",
    "                                plt.ylabel(\"Trade $P/L\")\n",
    "                                plt.xlabel(\"Trade Duration in Days\")\n",
    "                                plt.title(title)\n",
    "                                plt.legend()\n",
    "                                plt.savefig(f\"Plots/Scatter/{title.replace(\";\",\"_\").replace(\"/\",\"_\").replace(\"&\",\"_\").replace(\":\",\"_\")}.png\")\n",
    "                                # plt.show()\n",
    "                                plt.close()\n",
    "                                 \n",
    "                                bt_df['Sum'].cumsum().plot(label=\"Cum. P/L\", figsize=(12,6))\n",
    "                                plt.title(title)\n",
    "                                plt.legend()\n",
    "                                plt.savefig(f\"Plots/PL/{title.replace(\";\",\"_\").replace(\"/\",\"_\").replace(\"&\",\"_\").replace(\":\",\"_\")}.png\")\n",
    "                                # plt.show()\n",
    "                                plt.close()\n",
    "                                ############################### Plots\n",
    "                        except:\n",
    "                            continue\n",
    "            \n",
    "            display(dfx.iloc[[0,-1],:])\n",
    "            display(f\"ZScore Method is {z_score_method} and diff_period_list is {diff_period_list}\")\n",
    "            for trade_btdf_direction in ['Long/Short']: #'Long','Short',\n",
    "                print(f'global model is {global_model}')\n",
    "                print(f'model_num is {model_num}')\n",
    "                print(f'trade direction is {trade_btdf_direction}')\n",
    "                for info in ['$pnl','$pnl/trade','SR','Hit Ratio','trades','days/trade','max DD']:\n",
    "                    display(globals()[f'{global_model}_{model_num}_{trade_btdf_direction}_{info}'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
